{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import gym\n",
    "import ray\n",
    "from ray.rllib.agents import ppo, a3c, cql, ddpg, dqn\n",
    "\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from source.envs.env import WhitedBasicModel\n",
    "from source.solvers.ray_solver import RaySolver\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "A3C_Trainer = a3c.A3CTrainer\n",
    "PPO_Trainer = ppo.PPOTrainer\n",
    "DQNTrainer = dqn.DQNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'delta': 0.1, 'gamma': 1}\n",
      "{'delta': 0.1, 'gamma': 10}\n",
      "{'delta': 0.2, 'gamma': 1}\n",
      "{'delta': 0.2, 'gamma': 10}\n",
      "{'delta': 0.3, 'gamma': 1}\n",
      "{'delta': 0.3, 'gamma': 10}\n"
     ]
    }
   ],
   "source": [
    "from source.utils.useful_class import ParameterGrid\n",
    "\n",
    "grid = {\n",
    "        'delta': [0.1, 0.2, 0.3],\n",
    "        'gamma': [1, 10]\n",
    "    }\n",
    "pg = ParameterGrid(grid)\n",
    "for g in pg:\n",
    "    print(g)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 23:54:14,470\tINFO services.py:1340 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8266\u001B[39m\u001B[22m\n",
      "2022-01-12 23:54:15,518\tINFO trainer.py:745 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': True, 'episodes': 30, 'trainer_config': {'num_workers': 8, 'gamma': 0.99}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(RolloutWorker pid=6329)\u001B[0m 2022-01-12 23:54:17,315\tWARNING deprecation.py:46 -- DeprecationWarning: `convert_to_non_torch_type` has been deprecated. Use `ray/rllib/utils/numpy.py::convert_to_numpy` instead. This will raise an error in the future!\n",
      "2022-01-12 23:54:17,368\tWARNING deprecation.py:46 -- DeprecationWarning: `convert_to_non_torch_type` has been deprecated. Use `ray/rllib/utils/numpy.py::convert_to_numpy` instead. This will raise an error in the future!\n",
      "2022-01-12 23:54:17,375\tWARNING util.py:57 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-54-17\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 241.7726593017578\n",
      "        policy_entropy: 29.957176208496094\n",
      "        policy_loss: 156.156982421875\n",
      "        vf_loss: 169.4228973388672\n",
      "  num_steps_sampled: 10\n",
      "  num_steps_trained: 10\n",
      "iterations_since_restore: 1\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.9\n",
      "  ram_util_percent: 89.3\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "time_since_restore: 0.06924104690551758\n",
      "time_this_iter_s: 0.06924104690551758\n",
      "time_total_s: 0.06924104690551758\n",
      "timers:\n",
      "  apply_grad_throughput: 461.658\n",
      "  apply_grad_time_ms: 21.661\n",
      "  grad_wait_time_ms: 44.392\n",
      "  update_time_ms: 0.854\n",
      "timestamp: 1642053257\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 10\n",
      "training_iteration: 1\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-54-22\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 302.7172645516855\n",
      "episode_reward_mean: -845168579.3027468\n",
      "episode_reward_min: -36620151141.04773\n",
      "episodes_this_iter: 185\n",
      "episodes_total: 185\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 690.0694580078125\n",
      "        policy_entropy: 21.77489471435547\n",
      "        policy_loss: 192.33535766601562\n",
      "        vf_loss: 378.193603515625\n",
      "  num_steps_sampled: 18550\n",
      "  num_steps_trained: 18550\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 2\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 87.4857142857143\n",
      "  ram_util_percent: 89.3142857142857\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036732563326978156\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08113967452969886\n",
      "  mean_inference_ms: 1.0681358938125678\n",
      "  mean_raw_obs_processing_ms: 0.10784481391595442\n",
      "time_since_restore: 5.064733266830444\n",
      "time_this_iter_s: 4.995492219924927\n",
      "time_total_s: 5.064733266830444\n",
      "timers:\n",
      "  apply_grad_throughput: 11173.488\n",
      "  apply_grad_time_ms: 0.895\n",
      "  grad_wait_time_ms: 0.982\n",
      "  update_time_ms: 0.771\n",
      "timestamp: 1642053262\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 18550\n",
      "training_iteration: 2\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-54-27\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 322.2783251768117\n",
      "episode_reward_mean: 55.62157966533296\n",
      "episode_reward_min: -2949.909670644649\n",
      "episodes_this_iter: 199\n",
      "episodes_total: 384\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 445.4500427246094\n",
      "        policy_entropy: 20.773923873901367\n",
      "        policy_loss: 117.62480926513672\n",
      "        vf_loss: 114.18437194824219\n",
      "  num_steps_sampled: 38060\n",
      "  num_steps_trained: 38060\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 3\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 87.18571428571428\n",
      "  ram_util_percent: 89.29999999999998\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03624436747340119\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08026690124741036\n",
      "  mean_inference_ms: 1.037233682507561\n",
      "  mean_raw_obs_processing_ms: 0.10668704607120473\n",
      "time_since_restore: 10.053185224533081\n",
      "time_this_iter_s: 4.988451957702637\n",
      "time_total_s: 10.053185224533081\n",
      "timers:\n",
      "  apply_grad_throughput: 12393.417\n",
      "  apply_grad_time_ms: 0.807\n",
      "  grad_wait_time_ms: 0.987\n",
      "  update_time_ms: 0.675\n",
      "timestamp: 1642053267\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 38060\n",
      "training_iteration: 3\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-54-32\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 381.93036957615067\n",
      "episode_reward_mean: 121.85291660749397\n",
      "episode_reward_min: -714.6111407750745\n",
      "episodes_this_iter: 184\n",
      "episodes_total: 568\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 513.574462890625\n",
      "        policy_entropy: 16.342607498168945\n",
      "        policy_loss: 92.17383575439453\n",
      "        vf_loss: 200.34402465820312\n",
      "  num_steps_sampled: 56490\n",
      "  num_steps_trained: 56490\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 4\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 87.35714285714285\n",
      "  ram_util_percent: 89.41428571428571\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03662474970973075\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08092499657180464\n",
      "  mean_inference_ms: 1.0427926078162755\n",
      "  mean_raw_obs_processing_ms: 0.10737544471414419\n",
      "time_since_restore: 15.040333271026611\n",
      "time_this_iter_s: 4.98714804649353\n",
      "time_total_s: 15.040333271026611\n",
      "timers:\n",
      "  apply_grad_throughput: 10709.044\n",
      "  apply_grad_time_ms: 0.934\n",
      "  grad_wait_time_ms: 1.084\n",
      "  update_time_ms: 0.825\n",
      "timestamp: 1642053272\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 56490\n",
      "training_iteration: 4\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-54-37\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 338.22024211011575\n",
      "episode_reward_mean: -37.23736181024157\n",
      "episode_reward_min: -29372.555538128032\n",
      "episodes_this_iter: 176\n",
      "episodes_total: 744\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 161.520263671875\n",
      "        policy_entropy: 13.905911445617676\n",
      "        policy_loss: 28.68733787536621\n",
      "        vf_loss: 17.81125831604004\n",
      "  num_steps_sampled: 74430\n",
      "  num_steps_trained: 74430\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 5\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 87.4\n",
      "  ram_util_percent: 89.47142857142856\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03686665568608411\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08138569879929118\n",
      "  mean_inference_ms: 1.0498649901447026\n",
      "  mean_raw_obs_processing_ms: 0.1079516808632597\n",
      "time_since_restore: 20.028271198272705\n",
      "time_this_iter_s: 4.987937927246094\n",
      "time_total_s: 20.028271198272705\n",
      "timers:\n",
      "  apply_grad_throughput: 10092.894\n",
      "  apply_grad_time_ms: 0.991\n",
      "  grad_wait_time_ms: 1.132\n",
      "  update_time_ms: 0.884\n",
      "timestamp: 1642053277\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 74430\n",
      "training_iteration: 5\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-54-42\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 297.9852176141358\n",
      "episode_reward_mean: 168.00875520704992\n",
      "episode_reward_min: -135.61999199759882\n",
      "episodes_this_iter: 184\n",
      "episodes_total: 928\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 19.825145721435547\n",
      "        policy_entropy: 12.518011093139648\n",
      "        policy_loss: 11.018230438232422\n",
      "        vf_loss: 2.549978256225586\n",
      "  num_steps_sampled: 92900\n",
      "  num_steps_trained: 92900\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 6\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 87.85714285714286\n",
      "  ram_util_percent: 89.39999999999999\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036849235419749625\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08142060021446966\n",
      "  mean_inference_ms: 1.0475758238619393\n",
      "  mean_raw_obs_processing_ms: 0.10786402592155644\n",
      "time_since_restore: 25.015017986297607\n",
      "time_this_iter_s: 4.986746788024902\n",
      "time_total_s: 25.015017986297607\n",
      "timers:\n",
      "  apply_grad_throughput: 12808.991\n",
      "  apply_grad_time_ms: 0.781\n",
      "  grad_wait_time_ms: 0.866\n",
      "  update_time_ms: 0.63\n",
      "timestamp: 1642053282\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 92900\n",
      "training_iteration: 6\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-54-47\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 301.8066843622533\n",
      "episode_reward_mean: 166.18720439137897\n",
      "episode_reward_min: 88.08071800967592\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 1120\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 12998.74609375\n",
      "        policy_entropy: 11.472618103027344\n",
      "        policy_loss: -1012.7266235351562\n",
      "        vf_loss: 79258.8046875\n",
      "  num_steps_sampled: 112010\n",
      "  num_steps_trained: 112010\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 7\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 74.01428571428572\n",
      "  ram_util_percent: 89.37142857142858\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0367605937239737\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08124082761512331\n",
      "  mean_inference_ms: 1.0430555797197485\n",
      "  mean_raw_obs_processing_ms: 0.10766369533147264\n",
      "time_since_restore: 30.00539779663086\n",
      "time_this_iter_s: 4.990379810333252\n",
      "time_total_s: 30.00539779663086\n",
      "timers:\n",
      "  apply_grad_throughput: 12649.83\n",
      "  apply_grad_time_ms: 0.791\n",
      "  grad_wait_time_ms: 0.993\n",
      "  update_time_ms: 0.845\n",
      "timestamp: 1642053287\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 112010\n",
      "training_iteration: 7\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-54-52\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 298.45056147821606\n",
      "episode_reward_mean: 175.0161670810313\n",
      "episode_reward_min: 136.68798928968167\n",
      "episodes_this_iter: 184\n",
      "episodes_total: 1304\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 403.6147155761719\n",
      "        policy_entropy: 8.117775917053223\n",
      "        policy_loss: 79.34571838378906\n",
      "        vf_loss: 58.31587600708008\n",
      "  num_steps_sampled: 130500\n",
      "  num_steps_trained: 130500\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 8\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 89.18571428571428\n",
      "  ram_util_percent: 89.34285714285714\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03673757420862\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08124101891069872\n",
      "  mean_inference_ms: 1.042645777329258\n",
      "  mean_raw_obs_processing_ms: 0.10770943498497147\n",
      "time_since_restore: 34.99518179893494\n",
      "time_this_iter_s: 4.989784002304077\n",
      "time_total_s: 34.99518179893494\n",
      "timers:\n",
      "  apply_grad_throughput: 11877.843\n",
      "  apply_grad_time_ms: 0.842\n",
      "  grad_wait_time_ms: 0.873\n",
      "  update_time_ms: 0.684\n",
      "timestamp: 1642053292\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 130500\n",
      "training_iteration: 8\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-54-57\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 305.3141751240213\n",
      "episode_reward_mean: 167.96876703235287\n",
      "episode_reward_min: -992.893894234712\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 1496\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 547.9921875\n",
      "        policy_entropy: 10.624467849731445\n",
      "        policy_loss: 70.54541778564453\n",
      "        vf_loss: 133.61605834960938\n",
      "  num_steps_sampled: 149500\n",
      "  num_steps_trained: 149500\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 9\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 92.1125\n",
      "  ram_util_percent: 89.4\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0367385207114231\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08122913648736832\n",
      "  mean_inference_ms: 1.0414386013371455\n",
      "  mean_raw_obs_processing_ms: 0.10764715553702142\n",
      "time_since_restore: 39.987268924713135\n",
      "time_this_iter_s: 4.992087125778198\n",
      "time_total_s: 39.987268924713135\n",
      "timers:\n",
      "  apply_grad_throughput: 11796.996\n",
      "  apply_grad_time_ms: 0.848\n",
      "  grad_wait_time_ms: 1.01\n",
      "  update_time_ms: 0.775\n",
      "timestamp: 1642053297\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 149500\n",
      "training_iteration: 9\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-55-02\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 245.15419467793447\n",
      "episode_reward_mean: 185.2998146642942\n",
      "episode_reward_min: 150.79945656337424\n",
      "episodes_this_iter: 185\n",
      "episodes_total: 1681\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 86.37030792236328\n",
      "        policy_entropy: 9.013189315795898\n",
      "        policy_loss: 7.867027759552002\n",
      "        vf_loss: 8.469724655151367\n",
      "  num_steps_sampled: 168150\n",
      "  num_steps_trained: 168150\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 10\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 78.22857142857143\n",
      "  ram_util_percent: 89.31428571428572\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0367684165856713\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08124933061547435\n",
      "  mean_inference_ms: 1.0412757332526648\n",
      "  mean_raw_obs_processing_ms: 0.10764416612775642\n",
      "time_since_restore: 44.97504186630249\n",
      "time_this_iter_s: 4.9877729415893555\n",
      "time_total_s: 44.97504186630249\n",
      "timers:\n",
      "  apply_grad_throughput: 10104.565\n",
      "  apply_grad_time_ms: 0.99\n",
      "  grad_wait_time_ms: 1.207\n",
      "  update_time_ms: 0.832\n",
      "timestamp: 1642053302\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 168150\n",
      "training_iteration: 10\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-55-07\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 324.68697224218914\n",
      "episode_reward_mean: 188.78123543282547\n",
      "episode_reward_min: -48.38905761388195\n",
      "episodes_this_iter: 190\n",
      "episodes_total: 1871\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 158.7674102783203\n",
      "        policy_entropy: 7.741377830505371\n",
      "        policy_loss: -11.290481567382812\n",
      "        vf_loss: 17.475534439086914\n",
      "  num_steps_sampled: 186700\n",
      "  num_steps_trained: 186700\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 11\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 86.85714285714286\n",
      "  ram_util_percent: 89.37142857142858\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03678447741052667\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08131813835045389\n",
      "  mean_inference_ms: 1.0421579093304318\n",
      "  mean_raw_obs_processing_ms: 0.10769680359922723\n",
      "time_since_restore: 49.96579694747925\n",
      "time_this_iter_s: 4.990755081176758\n",
      "time_total_s: 49.96579694747925\n",
      "timers:\n",
      "  apply_grad_throughput: 12423.886\n",
      "  apply_grad_time_ms: 0.805\n",
      "  grad_wait_time_ms: 0.934\n",
      "  update_time_ms: 0.716\n",
      "timestamp: 1642053307\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 186700\n",
      "training_iteration: 11\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-55-12\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 270.3957180704333\n",
      "episode_reward_mean: 200.9416440994512\n",
      "episode_reward_min: 166.69966662575652\n",
      "episodes_this_iter: 169\n",
      "episodes_total: 2040\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 245.4161376953125\n",
      "        policy_entropy: 8.479063987731934\n",
      "        policy_loss: 21.86043930053711\n",
      "        vf_loss: 55.194095611572266\n",
      "  num_steps_sampled: 204100\n",
      "  num_steps_trained: 204100\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 12\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 87.72857142857143\n",
      "  ram_util_percent: 89.34285714285714\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036894990851753406\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08154537291575137\n",
      "  mean_inference_ms: 1.0457331378432655\n",
      "  mean_raw_obs_processing_ms: 0.10806497249507868\n",
      "time_since_restore: 54.95452284812927\n",
      "time_this_iter_s: 4.988725900650024\n",
      "time_total_s: 54.95452284812927\n",
      "timers:\n",
      "  apply_grad_throughput: 11830.938\n",
      "  apply_grad_time_ms: 0.845\n",
      "  grad_wait_time_ms: 1.002\n",
      "  update_time_ms: 0.809\n",
      "timestamp: 1642053312\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 204100\n",
      "training_iteration: 12\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-55-17\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 292.2925953850889\n",
      "episode_reward_mean: 205.27002501728484\n",
      "episode_reward_min: 169.13505701576366\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 2232\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 550.2609252929688\n",
      "        policy_entropy: 7.3080244064331055\n",
      "        policy_loss: 43.68575668334961\n",
      "        vf_loss: 289.0855407714844\n",
      "  num_steps_sampled: 222920\n",
      "  num_steps_trained: 222920\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 13\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 87.2\n",
      "  ram_util_percent: 89.20000000000002\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03687500849818845\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08154998235557671\n",
      "  mean_inference_ms: 1.0446181179090581\n",
      "  mean_raw_obs_processing_ms: 0.10806993657569118\n",
      "time_since_restore: 59.94734978675842\n",
      "time_this_iter_s: 4.99282693862915\n",
      "time_total_s: 59.94734978675842\n",
      "timers:\n",
      "  apply_grad_throughput: 11174.679\n",
      "  apply_grad_time_ms: 0.895\n",
      "  grad_wait_time_ms: 1.438\n",
      "  update_time_ms: 1.073\n",
      "timestamp: 1642053317\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 222920\n",
      "training_iteration: 13\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-55-22\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 260.2287108685144\n",
      "episode_reward_mean: 210.71573395494542\n",
      "episode_reward_min: 171.596385287615\n",
      "episodes_this_iter: 193\n",
      "episodes_total: 2425\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 226.1896514892578\n",
      "        policy_entropy: 7.0608296394348145\n",
      "        policy_loss: 10.10306453704834\n",
      "        vf_loss: 19.518848419189453\n",
      "  num_steps_sampled: 242580\n",
      "  num_steps_trained: 242580\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 14\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 86.55714285714285\n",
      "  ram_util_percent: 89.14285714285715\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03678714623217559\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08139502379659559\n",
      "  mean_inference_ms: 1.041604498878457\n",
      "  mean_raw_obs_processing_ms: 0.10787951145300903\n",
      "time_since_restore: 64.93561887741089\n",
      "time_this_iter_s: 4.988269090652466\n",
      "time_total_s: 64.93561887741089\n",
      "timers:\n",
      "  apply_grad_throughput: 11681.671\n",
      "  apply_grad_time_ms: 0.856\n",
      "  grad_wait_time_ms: 0.891\n",
      "  update_time_ms: 0.772\n",
      "timestamp: 1642053322\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 242580\n",
      "training_iteration: 14\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-55-27\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 266.2122696282807\n",
      "episode_reward_mean: 217.43731681647583\n",
      "episode_reward_min: 187.55949599176154\n",
      "episodes_this_iter: 199\n",
      "episodes_total: 2624\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 65.7263412475586\n",
      "        policy_entropy: 1.1564198732376099\n",
      "        policy_loss: 0.1893053501844406\n",
      "        vf_loss: 5.035254001617432\n",
      "  num_steps_sampled: 262430\n",
      "  num_steps_trained: 262430\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 15\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 86.67142857142856\n",
      "  ram_util_percent: 89.10000000000001\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03668587453683645\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08119762411691968\n",
      "  mean_inference_ms: 1.0379994013949512\n",
      "  mean_raw_obs_processing_ms: 0.10763320889875834\n",
      "time_since_restore: 69.9264805316925\n",
      "time_this_iter_s: 4.990861654281616\n",
      "time_total_s: 69.9264805316925\n",
      "timers:\n",
      "  apply_grad_throughput: 13061.892\n",
      "  apply_grad_time_ms: 0.766\n",
      "  grad_wait_time_ms: 1.103\n",
      "  update_time_ms: 0.718\n",
      "timestamp: 1642053327\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 262430\n",
      "training_iteration: 15\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-55-32\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 265.8047033533329\n",
      "episode_reward_mean: 221.68347926882856\n",
      "episode_reward_min: 186.95758994613004\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 2816\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 1025.575439453125\n",
      "        policy_entropy: 4.541136264801025\n",
      "        policy_loss: 184.0403594970703\n",
      "        vf_loss: 577.1558837890625\n",
      "  num_steps_sampled: 281730\n",
      "  num_steps_trained: 281730\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 16\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 86.28571428571429\n",
      "  ram_util_percent: 89.10000000000001\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03662622515929335\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08108736107163096\n",
      "  mean_inference_ms: 1.035916725470979\n",
      "  mean_raw_obs_processing_ms: 0.10753600406417128\n",
      "time_since_restore: 74.91678047180176\n",
      "time_this_iter_s: 4.990299940109253\n",
      "time_total_s: 74.91678047180176\n",
      "timers:\n",
      "  apply_grad_throughput: 12563.062\n",
      "  apply_grad_time_ms: 0.796\n",
      "  grad_wait_time_ms: 1.022\n",
      "  update_time_ms: 0.734\n",
      "timestamp: 1642053332\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 281730\n",
      "training_iteration: 16\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-55-37\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 275.7310539136499\n",
      "episode_reward_mean: 226.65725630489248\n",
      "episode_reward_min: 186.3508236156865\n",
      "episodes_this_iter: 200\n",
      "episodes_total: 3016\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 340.4071350097656\n",
      "        policy_entropy: 5.498796463012695\n",
      "        policy_loss: 11.223774909973145\n",
      "        vf_loss: 45.957889556884766\n",
      "  num_steps_sampled: 301390\n",
      "  num_steps_trained: 301390\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 17\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 75.32499999999999\n",
      "  ram_util_percent: 89.2\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03657286552371343\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08098900649501709\n",
      "  mean_inference_ms: 1.0341478775444268\n",
      "  mean_raw_obs_processing_ms: 0.10740646785808718\n",
      "time_since_restore: 79.90704560279846\n",
      "time_this_iter_s: 4.990265130996704\n",
      "time_total_s: 79.90704560279846\n",
      "timers:\n",
      "  apply_grad_throughput: 12686.561\n",
      "  apply_grad_time_ms: 0.788\n",
      "  grad_wait_time_ms: 0.898\n",
      "  update_time_ms: 0.698\n",
      "timestamp: 1642053337\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 301390\n",
      "training_iteration: 17\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-55-42\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 270.9051782101097\n",
      "episode_reward_mean: 232.18704798912097\n",
      "episode_reward_min: 193.19220147488164\n",
      "episodes_this_iter: 200\n",
      "episodes_total: 3216\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 124.97406005859375\n",
      "        policy_entropy: 5.1992716789245605\n",
      "        policy_loss: 2.886763095855713\n",
      "        vf_loss: 7.51741886138916\n",
      "  num_steps_sampled: 321130\n",
      "  num_steps_trained: 321130\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 18\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 73.75714285714285\n",
      "  ram_util_percent: 89.20000000000002\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036521051466234175\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0808854199020182\n",
      "  mean_inference_ms: 1.0323093482072394\n",
      "  mean_raw_obs_processing_ms: 0.1072525993347348\n",
      "time_since_restore: 84.89626479148865\n",
      "time_this_iter_s: 4.9892191886901855\n",
      "time_total_s: 84.89626479148865\n",
      "timers:\n",
      "  apply_grad_throughput: 11734.945\n",
      "  apply_grad_time_ms: 0.852\n",
      "  grad_wait_time_ms: 0.918\n",
      "  update_time_ms: 0.748\n",
      "timestamp: 1642053342\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 321130\n",
      "training_iteration: 18\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-55-47\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 283.5330311450897\n",
      "episode_reward_mean: 232.05571382737207\n",
      "episode_reward_min: 193.092907449443\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 3408\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 20754.501953125\n",
      "        policy_entropy: 6.010641098022461\n",
      "        policy_loss: -1331.9739990234375\n",
      "        vf_loss: 256098.234375\n",
      "  num_steps_sampled: 340790\n",
      "  num_steps_trained: 340790\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 19\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 85.89999999999999\n",
      "  ram_util_percent: 89.10000000000001\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03647326413313512\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08078035043006948\n",
      "  mean_inference_ms: 1.0306443234670792\n",
      "  mean_raw_obs_processing_ms: 0.10717308506632318\n",
      "time_since_restore: 89.8859658241272\n",
      "time_this_iter_s: 4.98970103263855\n",
      "time_total_s: 89.8859658241272\n",
      "timers:\n",
      "  apply_grad_throughput: 11978.25\n",
      "  apply_grad_time_ms: 0.835\n",
      "  grad_wait_time_ms: 0.922\n",
      "  update_time_ms: 0.724\n",
      "timestamp: 1642053347\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 340790\n",
      "training_iteration: 19\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-55-52\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 271.5263179065926\n",
      "episode_reward_mean: 235.060498899112\n",
      "episode_reward_min: 199.27225093267953\n",
      "episodes_this_iter: 187\n",
      "episodes_total: 3595\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 119.30958557128906\n",
      "        policy_entropy: 4.541244029998779\n",
      "        policy_loss: 10.134923934936523\n",
      "        vf_loss: 19.966703414916992\n",
      "  num_steps_sampled: 359430\n",
      "  num_steps_trained: 359430\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 20\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 88.00000000000001\n",
      "  ram_util_percent: 89.18571428571428\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03651111999883705\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08085094964887433\n",
      "  mean_inference_ms: 1.0314850288223176\n",
      "  mean_raw_obs_processing_ms: 0.10728026712655712\n",
      "time_since_restore: 94.87718272209167\n",
      "time_this_iter_s: 4.9912168979644775\n",
      "time_total_s: 94.87718272209167\n",
      "timers:\n",
      "  apply_grad_throughput: 12411.019\n",
      "  apply_grad_time_ms: 0.806\n",
      "  grad_wait_time_ms: 0.895\n",
      "  update_time_ms: 0.688\n",
      "timestamp: 1642053352\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 359430\n",
      "training_iteration: 20\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-55-57\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 306.04069057290366\n",
      "episode_reward_mean: 244.98264110553535\n",
      "episode_reward_min: 202.62289392806704\n",
      "episodes_this_iter: 205\n",
      "episodes_total: 3800\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 335.9664306640625\n",
      "        policy_entropy: 4.867542266845703\n",
      "        policy_loss: 14.823145866394043\n",
      "        vf_loss: 54.962913513183594\n",
      "  num_steps_sampled: 379600\n",
      "  num_steps_trained: 379600\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 21\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 87.52857142857144\n",
      "  ram_util_percent: 89.20000000000002\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03643032041199824\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08069750378106529\n",
      "  mean_inference_ms: 1.0290211090097872\n",
      "  mean_raw_obs_processing_ms: 0.10712371981946882\n",
      "time_since_restore: 99.86985754966736\n",
      "time_this_iter_s: 4.992674827575684\n",
      "time_total_s: 99.86985754966736\n",
      "timers:\n",
      "  apply_grad_throughput: 13108.839\n",
      "  apply_grad_time_ms: 0.763\n",
      "  grad_wait_time_ms: 0.896\n",
      "  update_time_ms: 0.649\n",
      "timestamp: 1642053357\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 379600\n",
      "training_iteration: 21\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-56-02\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 314.0083022791247\n",
      "episode_reward_mean: 245.00696931432608\n",
      "episode_reward_min: 187.49671407570517\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 3992\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 357.8151550292969\n",
      "        policy_entropy: 4.749382972717285\n",
      "        policy_loss: 25.43922996520996\n",
      "        vf_loss: 75.06024932861328\n",
      "  num_steps_sampled: 399300\n",
      "  num_steps_trained: 399300\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 22\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 86.52857142857142\n",
      "  ram_util_percent: 89.1857142857143\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03639314198435936\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08060946653047851\n",
      "  mean_inference_ms: 1.0275885708914279\n",
      "  mean_raw_obs_processing_ms: 0.10702838845596217\n",
      "time_since_restore: 104.86172842979431\n",
      "time_this_iter_s: 4.991870880126953\n",
      "time_total_s: 104.86172842979431\n",
      "timers:\n",
      "  apply_grad_throughput: 12885.331\n",
      "  apply_grad_time_ms: 0.776\n",
      "  grad_wait_time_ms: 0.914\n",
      "  update_time_ms: 0.671\n",
      "timestamp: 1642053362\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 399300\n",
      "training_iteration: 22\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-56-07\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 297.32622911195864\n",
      "episode_reward_mean: 249.63343671920387\n",
      "episode_reward_min: 203.51980459562213\n",
      "episodes_this_iter: 202\n",
      "episodes_total: 4194\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 344.17706298828125\n",
      "        policy_entropy: 4.779732704162598\n",
      "        policy_loss: 16.597963333129883\n",
      "        vf_loss: 84.81062316894531\n",
      "  num_steps_sampled: 419410\n",
      "  num_steps_trained: 419410\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 23\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 74.08571428571427\n",
      "  ram_util_percent: 89.10000000000001\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036338328869421496\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08048874698718757\n",
      "  mean_inference_ms: 1.0256478376163973\n",
      "  mean_raw_obs_processing_ms: 0.10690028878397209\n",
      "time_since_restore: 109.85304474830627\n",
      "time_this_iter_s: 4.991316318511963\n",
      "time_total_s: 109.85304474830627\n",
      "timers:\n",
      "  apply_grad_throughput: 12066.12\n",
      "  apply_grad_time_ms: 0.829\n",
      "  grad_wait_time_ms: 0.963\n",
      "  update_time_ms: 0.67\n",
      "timestamp: 1642053367\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 419410\n",
      "training_iteration: 23\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-56-12\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 298.542489560374\n",
      "episode_reward_mean: 251.3031512150622\n",
      "episode_reward_min: 216.85331293395095\n",
      "episodes_this_iter: 198\n",
      "episodes_total: 4392\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 144.69349670410156\n",
      "        policy_entropy: 0.08497649431228638\n",
      "        policy_loss: 0.012582986615598202\n",
      "        vf_loss: 11.582841873168945\n",
      "  num_steps_sampled: 439260\n",
      "  num_steps_trained: 439260\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 24\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 73.87142857142855\n",
      "  ram_util_percent: 89.14285714285714\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03628331424486109\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08039817304177398\n",
      "  mean_inference_ms: 1.0240366252786088\n",
      "  mean_raw_obs_processing_ms: 0.10680697428906524\n",
      "time_since_restore: 114.84446048736572\n",
      "time_this_iter_s: 4.991415739059448\n",
      "time_total_s: 114.84446048736572\n",
      "timers:\n",
      "  apply_grad_throughput: 13185.903\n",
      "  apply_grad_time_ms: 0.758\n",
      "  grad_wait_time_ms: 0.943\n",
      "  update_time_ms: 0.697\n",
      "timestamp: 1642053372\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 439260\n",
      "training_iteration: 24\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-56-17\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 307.0864997872027\n",
      "episode_reward_mean: 254.158106427486\n",
      "episode_reward_min: 201.5820857408578\n",
      "episodes_this_iter: 200\n",
      "episodes_total: 4592\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 30574.33984375\n",
      "        policy_entropy: 4.66175651550293\n",
      "        policy_loss: -2145.695556640625\n",
      "        vf_loss: 363950.0\n",
      "  num_steps_sampled: 459240\n",
      "  num_steps_trained: 459240\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 25\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 87.0375\n",
      "  ram_util_percent: 89.15\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03624683302750184\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08031822221391965\n",
      "  mean_inference_ms: 1.0227028399676534\n",
      "  mean_raw_obs_processing_ms: 0.10672409948537023\n",
      "time_since_restore: 119.8363606929779\n",
      "time_this_iter_s: 4.991900205612183\n",
      "time_total_s: 119.8363606929779\n",
      "timers:\n",
      "  apply_grad_throughput: 13487.809\n",
      "  apply_grad_time_ms: 0.741\n",
      "  grad_wait_time_ms: 0.965\n",
      "  update_time_ms: 0.674\n",
      "timestamp: 1642053377\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 459240\n",
      "training_iteration: 25\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-56-22\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 308.3000748301486\n",
      "episode_reward_mean: 258.2924524202337\n",
      "episode_reward_min: 203.19760483205198\n",
      "episodes_this_iter: 200\n",
      "episodes_total: 4792\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 103.84843444824219\n",
      "        policy_entropy: 1.6535534858703613\n",
      "        policy_loss: 0.7398675084114075\n",
      "        vf_loss: 3.32513165473938\n",
      "  num_steps_sampled: 479280\n",
      "  num_steps_trained: 479280\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 26\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 87.17142857142858\n",
      "  ram_util_percent: 89.10000000000001\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036199692944920626\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08022669732778098\n",
      "  mean_inference_ms: 1.0211125202886082\n",
      "  mean_raw_obs_processing_ms: 0.10661872451822692\n",
      "time_since_restore: 124.82793998718262\n",
      "time_this_iter_s: 4.991579294204712\n",
      "time_total_s: 124.82793998718262\n",
      "timers:\n",
      "  apply_grad_throughput: 12706.547\n",
      "  apply_grad_time_ms: 0.787\n",
      "  grad_wait_time_ms: 0.991\n",
      "  update_time_ms: 0.678\n",
      "timestamp: 1642053382\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 479280\n",
      "training_iteration: 26\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-56-27\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 314.8777061698886\n",
      "episode_reward_mean: 261.54783743728\n",
      "episode_reward_min: 215.6254298967043\n",
      "episodes_this_iter: 202\n",
      "episodes_total: 4994\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 290.643798828125\n",
      "        policy_entropy: 1.1962838172912598\n",
      "        policy_loss: -0.00869971513748169\n",
      "        vf_loss: 20.156166076660156\n",
      "  num_steps_sampled: 499400\n",
      "  num_steps_trained: 499400\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 27\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 87.21428571428574\n",
      "  ram_util_percent: 89.10000000000001\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036151564682966375\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0801274437543765\n",
      "  mean_inference_ms: 1.0195754763475406\n",
      "  mean_raw_obs_processing_ms: 0.10651423890767737\n",
      "time_since_restore: 129.82038283348083\n",
      "time_this_iter_s: 4.992442846298218\n",
      "time_total_s: 129.82038283348083\n",
      "timers:\n",
      "  apply_grad_throughput: 12502.769\n",
      "  apply_grad_time_ms: 0.8\n",
      "  grad_wait_time_ms: 0.933\n",
      "  update_time_ms: 0.687\n",
      "timestamp: 1642053387\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 499400\n",
      "training_iteration: 27\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-56-32\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 314.3939126291373\n",
      "episode_reward_mean: 260.35388175620875\n",
      "episode_reward_min: 227.21714357416732\n",
      "episodes_this_iter: 199\n",
      "episodes_total: 5193\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 88.19147491455078\n",
      "        policy_entropy: 3.9680697917938232\n",
      "        policy_loss: -5.717169284820557\n",
      "        vf_loss: 35.03707504272461\n",
      "  num_steps_sampled: 519380\n",
      "  num_steps_trained: 519380\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 28\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 88.45714285714284\n",
      "  ram_util_percent: 89.10000000000001\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036118411180670426\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08007604775213475\n",
      "  mean_inference_ms: 1.0186965193159851\n",
      "  mean_raw_obs_processing_ms: 0.10647771544742186\n",
      "time_since_restore: 134.8113350868225\n",
      "time_this_iter_s: 4.990952253341675\n",
      "time_total_s: 134.8113350868225\n",
      "timers:\n",
      "  apply_grad_throughput: 12626.22\n",
      "  apply_grad_time_ms: 0.792\n",
      "  grad_wait_time_ms: 0.885\n",
      "  update_time_ms: 0.653\n",
      "timestamp: 1642053392\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 519380\n",
      "training_iteration: 28\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-56-37\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 320.3975634275435\n",
      "episode_reward_mean: 265.7114525697415\n",
      "episode_reward_min: 215.20475213128873\n",
      "episodes_this_iter: 206\n",
      "episodes_total: 5399\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 2389.7138671875\n",
      "        policy_entropy: 4.287552833557129\n",
      "        policy_loss: 24.98590087890625\n",
      "        vf_loss: 292.01556396484375\n",
      "  num_steps_sampled: 539510\n",
      "  num_steps_trained: 539510\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 29\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 87.0142857142857\n",
      "  ram_util_percent: 89.10000000000001\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03608979252016565\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0799888130555899\n",
      "  mean_inference_ms: 1.0176156487660042\n",
      "  mean_raw_obs_processing_ms: 0.10638814730133665\n",
      "time_since_restore: 139.8028540611267\n",
      "time_this_iter_s: 4.991518974304199\n",
      "time_total_s: 139.8028540611267\n",
      "timers:\n",
      "  apply_grad_throughput: 13333.028\n",
      "  apply_grad_time_ms: 0.75\n",
      "  grad_wait_time_ms: 0.79\n",
      "  update_time_ms: 0.694\n",
      "timestamp: 1642053397\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 539510\n",
      "training_iteration: 29\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-12_23-56-42\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 316.1307148252423\n",
      "episode_reward_mean: 266.1169702777304\n",
      "episode_reward_min: 213.5381849573563\n",
      "episodes_this_iter: 193\n",
      "episodes_total: 5592\n",
      "experiment_id: 82484fc6cad346d986a203a079c55af9\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 1316.7021484375\n",
      "        policy_entropy: 4.0497846603393555\n",
      "        policy_loss: 15.47548770904541\n",
      "        vf_loss: 68.67918395996094\n",
      "  num_steps_sampled: 559300\n",
      "  num_steps_trained: 559300\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 30\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 86.75714285714287\n",
      "  ram_util_percent: 89.10000000000001\n",
      "pid: 6297\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03606707199452834\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07996706534040003\n",
      "  mean_inference_ms: 1.0169655174471826\n",
      "  mean_raw_obs_processing_ms: 0.10634606330480902\n",
      "time_since_restore: 144.79412484169006\n",
      "time_this_iter_s: 4.9912707805633545\n",
      "time_total_s: 144.79412484169006\n",
      "timers:\n",
      "  apply_grad_throughput: 8791.063\n",
      "  apply_grad_time_ms: 1.138\n",
      "  grad_wait_time_ms: 1.054\n",
      "  update_time_ms: 1.051\n",
      "timestamp: 1642053402\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 559300\n",
      "training_iteration: 30\n",
      "trial_id: default\n",
      "\n",
      "checkpoint saved at /Users/mingweima/ray_results/A3C_my-env_2022-01-12_23-54-15mdui1e88/checkpoint_000030/checkpoint-30\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()\n",
    "env = WhitedBasicModel(env_config={\"structural_params\": {\"gamma\": [0.9,0.96],\n",
    "                                                         \"delta\": [0.1, 0.3],\n",
    "                                                         \"theta\": [0.5, 0.8],\n",
    "                                                         \"rho\": [0.3, 0.8],\n",
    "                                                         \"sigma\": [0., 0.15],\n",
    "                                                        }, \n",
    "                                   \"env_params\": {\"psi_func\": lambda i, k: 0.01*i**2/(2*k)\n",
    "                                                 },\n",
    "                                   \"is_mutable\": True,\n",
    "                                  })\n",
    "solver = RaySolver(env=env,\n",
    "                   trainer=A3C_Trainer,\n",
    "                   solver_params={\"verbose\": True, \"episodes\": 30,\n",
    "                                  \"trainer_config\": {\n",
    "                                      \"num_workers\": 8,\n",
    "                                      \"gamma\": env.current_structural_params.get(\"gamma\", 0.99),\n",
    "                                  }\n",
    "                                  })\n",
    "solver.train()\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mingweima/ray_results/A3C_my-env_2022-01-04_15-11-160hhhuamk/checkpoint_000030/checkpoint-30'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.55043662 0.94101024 0.93119333 0.29166863 0.6912884  0.67761639\n",
      " 0.11232307] 16 0.1543490304709142 False {}\n",
      "[2.40385365 1.07871056 0.93119333 0.29166863 0.6912884  0.67761639\n",
      " 0.11232307] 16 -0.03688304788944441 False {}\n",
      "[3.72702289 1.20395291 0.93119333 0.29166863 0.6912884  0.67761639\n",
      " 0.11232307] 16 -0.05483967130247369 False {}\n",
      "[5.77851295 1.12355947 0.93119333 0.29166863 0.6912884  0.67761639\n",
      " 0.11232307] 16 -0.16235066277430743 False {}\n",
      "[5.91789579 0.8079899  0.93119333 0.29166863 0.6912884  0.67761639\n",
      " 0.11232307] 6 1.9500532256119953 False {}\n",
      "[9.17532253 0.98601341 0.93119333 0.29166863 0.6912884  0.67761639\n",
      " 0.11232307] 16 -2.242648829290617 False {}\n",
      "[14.22575665  1.07891905  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -3.1952659595525548 False {}\n",
      "[14.56889439  1.06649446  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 2.2628946204890905 False {}\n",
      "[22.58814812  1.07647991  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -5.524691941831308 False {}\n",
      "[17.18874359  0.98477125  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 8.098958927815783 False {}\n",
      "[26.65005875  1.14944577  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -7.50098228919631 False {}\n",
      "[20.27970695  1.15003443  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 9.715774967307835 False {}\n",
      "[15.43210602  1.02888405  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 8.14253111058142 False {}\n",
      "[23.92650223  0.98964018  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -6.228186886051782 False {}\n",
      "[18.20718193  0.95576888  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 7.625851333853958 False {}\n",
      "[18.64635468  0.82898754  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 1.3459577312795519 False {}\n",
      "[28.90999222  0.77134025  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -9.503686226121111 False {}\n",
      "[21.99943352  0.83159131  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 6.3711919347390324 False {}\n",
      "[16.74075317  0.99075025  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 5.8871943172261085 False {}\n",
      "[17.14455414  1.08671081  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 1.6544725160140494 False {}\n",
      "[17.55809593  1.34164238  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 2.3264788830309344 False {}\n",
      "[17.98161125  1.35626733  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 4.172478155405172 False {}\n",
      "[13.68334007  1.02946496  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 9.04860250062788 False {}\n",
      "[21.21515083  0.9210012   0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -5.290052053034627 False {}\n",
      "[21.72687912  0.83892691  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 0.8993854843291267 False {}\n",
      "[22.25094986  0.99675477  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 0.17456999853881605 False {}\n",
      "[34.49868774  1.03142667  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -10.305259988250539 False {}\n",
      "[26.25222397  1.08428633  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 10.110038669822956 False {}\n",
      "[21.35866547  1.047382    0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 2 7.615146104270975 False {}\n",
      "[33.11525726  1.11769319  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -9.367883573546502 False {}\n",
      "[25.19948387  1.14690018  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 10.819837095611975 False {}\n",
      "[19.1758728   1.18699098  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 9.346482600136463 False {}\n",
      "[14.59212875  1.21017194  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 8.13584541153054 False {}\n",
      "[22.6241703   1.04531395  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -4.620354535335703 False {}\n",
      "[17.21615601  0.98304611  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 7.838095872303343 False {}\n",
      "[17.63142395  1.14388287  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 1.5848468029435905 False {}\n",
      "[27.3364048   1.16869652  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -6.593818491836615 False {}\n",
      "[20.80199051  1.29338717  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 10.066334368916078 False {}\n",
      "[32.25216675  1.28966987  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -7.049316755607775 False {}\n",
      "[24.54270363  1.11334825  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 12.536098763065088 False {}\n",
      "[18.67608833  1.23446155  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 8.88138888439315 False {}\n",
      "[14.21181107  1.29943478  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 8.355840798940006 False {}\n",
      "[22.03451347  1.13198078  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -3.8792953253274796 False {}\n",
      "[22.5660038   0.98095441  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 2.6316225405246954 False {}\n",
      "[34.98715973  0.8515839   0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -10.624794702600065 False {}\n",
      "[26.62393188  0.77123332  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 8.100998076552743 False {}\n",
      "[20.25982666  0.87487161  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 6.053582213631551 False {}\n",
      "[15.41697788  0.88506991  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 5.935160127897583 False {}\n",
      "[15.78884888  0.97384948  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 0.9882486903425844 False {}\n",
      "[12.0147295   0.92656571  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 5.7286951350837825 False {}\n",
      "[9.14276409 0.87034023 0.93119333 0.29166863 0.6912884  0.67761639\n",
      " 0.11232307] 1 4.534854405798698 False {}\n",
      "[9.36329556 0.98364073 0.93119333 0.29166863 0.6912884  0.67761639\n",
      " 0.11232307] 6 1.126815704786729 False {}\n",
      "[7.12512112 0.98080254 0.93119333 0.29166863 0.6912884  0.67761639\n",
      " 0.11232307] 1 4.124214536396254 False {}\n",
      "[11.04704857  0.96784472  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -2.2137686606146283 False {}\n",
      "[17.12774849  1.09238935  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -4.248759146367741 False {}\n",
      "[26.55548859  1.0007534   0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -6.699786792756594 False {}\n",
      "[20.20774269  0.83346754  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 8.258667667077003 False {}\n",
      "[20.69517136  0.75754207  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 0.26705615815729633 False {}\n",
      "[15.74825859  0.82113695  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 5.062995583509145 False {}\n",
      "[24.41667747  0.73560756  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -7.796138470374646 False {}\n",
      "[18.58018684  0.74636656  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 5.412460387085908 False {}\n",
      "[28.80740166  0.73074251  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -10.085937978893403 False {}\n",
      "[21.92136574  0.8895247   0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 5.942799958699361 False {}\n",
      "[16.68134689  0.86973202  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 6.363627095516579 False {}\n",
      "[17.08371544  0.87109929  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 0.8094360312215976 False {}\n",
      "[26.48721886  0.8494612   0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -8.250487962932446 False {}\n",
      "[20.15579224  0.8164202   0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 6.787806242877419 False {}\n",
      "[31.25027847  1.01767397  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -10.53402699532121 False {}\n",
      "[23.78030396  1.00819659  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 9.344464496275755 False {}\n",
      "[18.0959301   1.03501379  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 7.761884554545518 False {}\n",
      "[13.77033234  1.06865489  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 6.708539541000469 False {}\n",
      "[21.35002708  0.87636685  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -5.095871501366219 False {}\n",
      "[26.35975075  0.92754817  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 10 -3.9939283502771215 False {}\n",
      "[20.05879402  1.09676898  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 7.516926532668917 False {}\n",
      "[20.54262924  0.9576571   0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 2.3729699507107016 False {}\n",
      "[15.63218021  1.14737713  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 6.656616876866659 False {}\n",
      "[24.23670578  1.37708867  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -5.543667302210506 False {}\n",
      "[18.4432354   1.31962276  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 11.19881489284883 False {}\n",
      "[28.59506798  1.42449391  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -5.699432101849867 False {}\n",
      "[21.75978661  0.98981684  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 12.961576264371917 False {}\n",
      "[16.55839157  0.8645888   0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 7.177064758423633 False {}\n",
      "[12.60032272  0.94641787  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 5.146976470989113 False {}\n",
      "[12.90425301  0.9992311   0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 1.4692818415575988 False {}\n",
      "[13.21551418  0.99987805  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 1.7732120539681775 False {}\n",
      "[13.53428364  1.02668834  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 6 1.775881139379229 False {}\n",
      "[20.98404884  0.98103923  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -5.228196527622837 False {}\n",
      "[15.96808338  0.98508096  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 6.939675382886169 False {}\n",
      "[24.7575016   0.93551922  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -6.815881755631266 False {}\n",
      "[18.83954239  0.85141331  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 7.29678142048788 False {}\n",
      "[29.20951653  0.98117274  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -9.451576339153085 False {}\n",
      "[22.22735977  0.79113883  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 8.574448108322246 False {}\n",
      "[34.46211243  0.90304238  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -12.046014989144314 False {}\n",
      "[26.22439003  0.93053263  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 8.619821241208163 False {}\n",
      "[19.95578957  0.85025597  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 7.520966998846782 False {}\n",
      "[30.94018745  0.98110741  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -10.141646267594101 False {}\n",
      "[23.54433632  1.09112179  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 8.893127766180555 False {}\n",
      "[17.91636848  0.97593975  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 8.448683123395531 False {}\n",
      "[27.77819443  1.00233781  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 16 -7.976683697729929 False {}\n",
      "[21.13817596  1.01854014  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 8.515293632110925 False {}\n",
      "[16.08536911  0.96968502  0.93119333  0.29166863  0.6912884   0.67761639\n",
      "  0.11232307] 1 7.281422496084834 True {}\n"
     ]
    }
   ],
   "source": [
    "# run until episode ends\n",
    "episode_reward = 0\n",
    "done = False\n",
    "obs = env.reset()\n",
    "while not done:\n",
    "    action = solver.act(obs)\n",
    "    obs, reward, done, info = env.step(action, resample_param=False)\n",
    "    episode_reward += reward\n",
    "    print(obs, action, reward, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test trained agent for a single episode. Return the episode reward\"\"\"\n",
    "cp = []\n",
    "for eps in range(2):\n",
    "      # instantiate env class\n",
    "      episode_reward = 0\n",
    "      done = False\n",
    "      obs = env.reset()\n",
    "      # run until episode ends\n",
    "      caps = []\n",
    "      while not done:\n",
    "          action = solver.trainer.compute_single_action(obs, clip_action=True)\n",
    "          obs, reward, done, info = env.step(action, resample_param=False)\n",
    "          episode_reward += reward\n",
    "          #print(action, obs, reward, done)\n",
    "          caps += [obs[0]]\n",
    "      cp += [ [caps] ]\n",
    "cp = np.squeeze(np.array(cp)).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(cp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}