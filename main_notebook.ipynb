{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import gym\n",
    "import ray\n",
    "from ray.rllib.agents import ppo, a3c, cql, ddpg, dqn\n",
    "\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from source.envs.env import WhitedBasicModel\n",
    "from source.solvers.ray_solver import RaySolver\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "A3C_Trainer = a3c.A3CTrainer\n",
    "PPO_Trainer = ppo.PPOTrainer\n",
    "DQNTrainer = dqn.DQNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:36:20,245\tINFO services.py:1340 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n",
      "2022-01-04 15:36:21,299\tINFO trainer.py:745 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2022-01-04 15:36:23,325\tWARNING deprecation.py:46 -- DeprecationWarning: `convert_to_non_torch_type` has been deprecated. Use `ray/rllib/utils/numpy.py::convert_to_numpy` instead. This will raise an error in the future!\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=48898)\u001B[0m 2022-01-04 15:36:23,287\tWARNING deprecation.py:46 -- DeprecationWarning: `convert_to_non_torch_type` has been deprecated. Use `ray/rllib/utils/numpy.py::convert_to_numpy` instead. This will raise an error in the future!\n",
      "2022-01-04 15:36:23,342\tWARNING util.py:57 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-36-23\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 807.92919921875\n",
      "        policy_entropy: 29.957077026367188\n",
      "        policy_loss: -445.6387939453125\n",
      "        vf_loss: 1364.88720703125\n",
      "  num_steps_sampled: 10\n",
      "  num_steps_trained: 10\n",
      "iterations_since_restore: 1\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 52.2\n",
      "  ram_util_percent: 90.0\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "time_since_restore: 0.055021047592163086\n",
      "time_this_iter_s: 0.055021047592163086\n",
      "time_total_s: 0.055021047592163086\n",
      "timers:\n",
      "  apply_grad_throughput: 623.79\n",
      "  apply_grad_time_ms: 16.031\n",
      "  grad_wait_time_ms: 35.189\n",
      "  update_time_ms: 0.97\n",
      "timestamp: 1641332183\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 10\n",
      "training_iteration: 1\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-36-28\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 1397.5310692981473\n",
      "episode_reward_mean: -24890415828040.86\n",
      "episode_reward_min: -4169323214631324.5\n",
      "episodes_this_iter: 168\n",
      "episodes_total: 168\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 1204.781982421875\n",
      "        policy_entropy: 21.557523727416992\n",
      "        policy_loss: -290.4139404296875\n",
      "        vf_loss: 974.2313232421875\n",
      "  num_steps_sampled: 16840\n",
      "  num_steps_trained: 16840\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 2\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 96.07142857142856\n",
      "  ram_util_percent: 89.81428571428572\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03767945793523987\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06859610320246995\n",
      "  mean_inference_ms: 1.107075744701127\n",
      "  mean_raw_obs_processing_ms: 0.11187162441095769\n",
      "time_since_restore: 5.05267596244812\n",
      "time_this_iter_s: 4.997654914855957\n",
      "time_total_s: 5.05267596244812\n",
      "timers:\n",
      "  apply_grad_throughput: 11110.15\n",
      "  apply_grad_time_ms: 0.9\n",
      "  grad_wait_time_ms: 1.05\n",
      "  update_time_ms: 0.727\n",
      "timestamp: 1641332188\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 16840\n",
      "training_iteration: 2\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-36-33\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 2640.534218174569\n",
      "episode_reward_mean: -11826.775860658938\n",
      "episode_reward_min: -702279.8964846076\n",
      "episodes_this_iter: 184\n",
      "episodes_total: 352\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 28233.1875\n",
      "        policy_entropy: 19.85639762878418\n",
      "        policy_loss: -2293.552978515625\n",
      "        vf_loss: 148470.328125\n",
      "  num_steps_sampled: 34910\n",
      "  num_steps_trained: 34910\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 3\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 95.12857142857142\n",
      "  ram_util_percent: 89.74285714285713\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03762312710372328\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06837556823862663\n",
      "  mean_inference_ms: 1.0847416292215164\n",
      "  mean_raw_obs_processing_ms: 0.10962701908420097\n",
      "time_since_restore: 10.041055917739868\n",
      "time_this_iter_s: 4.988379955291748\n",
      "time_total_s: 10.041055917739868\n",
      "timers:\n",
      "  apply_grad_throughput: 12505.006\n",
      "  apply_grad_time_ms: 0.8\n",
      "  grad_wait_time_ms: 1.077\n",
      "  update_time_ms: 0.759\n",
      "timestamp: 1641332193\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 34910\n",
      "training_iteration: 3\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-36-38\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 9950.971002295904\n",
      "episode_reward_mean: -13787.164460732763\n",
      "episode_reward_min: -2334246.5780518064\n",
      "episodes_this_iter: 176\n",
      "episodes_total: 528\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 5314.3818359375\n",
      "        policy_entropy: 22.550926208496094\n",
      "        policy_loss: -1391.1568603515625\n",
      "        vf_loss: 15926.4423828125\n",
      "  num_steps_sampled: 52710\n",
      "  num_steps_trained: 52710\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 4\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 81.8\n",
      "  ram_util_percent: 89.8142857142857\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03766561178511057\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06836782643552236\n",
      "  mean_inference_ms: 1.0791283269977934\n",
      "  mean_raw_obs_processing_ms: 0.10912457624095612\n",
      "time_since_restore: 15.028867959976196\n",
      "time_this_iter_s: 4.987812042236328\n",
      "time_total_s: 15.028867959976196\n",
      "timers:\n",
      "  apply_grad_throughput: 11932.247\n",
      "  apply_grad_time_ms: 0.838\n",
      "  grad_wait_time_ms: 1.046\n",
      "  update_time_ms: 0.82\n",
      "timestamp: 1641332198\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 52710\n",
      "training_iteration: 4\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-36-43\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 2836.258832349981\n",
      "episode_reward_mean: -166.5920381219628\n",
      "episode_reward_min: -16829.004719903478\n",
      "episodes_this_iter: 179\n",
      "episodes_total: 707\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 55.0836181640625\n",
      "        policy_entropy: 20.684429168701172\n",
      "        policy_loss: 0.23741590976715088\n",
      "        vf_loss: 6.687199115753174\n",
      "  num_steps_sampled: 70620\n",
      "  num_steps_trained: 70620\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 5\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 81.7\n",
      "  ram_util_percent: 89.75714285714285\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03754497991649112\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06822041147699416\n",
      "  mean_inference_ms: 1.075875777145149\n",
      "  mean_raw_obs_processing_ms: 0.10882620192453459\n",
      "time_since_restore: 20.018332958221436\n",
      "time_this_iter_s: 4.989464998245239\n",
      "time_total_s: 20.018332958221436\n",
      "timers:\n",
      "  apply_grad_throughput: 9844.166\n",
      "  apply_grad_time_ms: 1.016\n",
      "  grad_wait_time_ms: 0.928\n",
      "  update_time_ms: 0.748\n",
      "timestamp: 1641332203\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 70620\n",
      "training_iteration: 5\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-36-48\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5409.933246370288\n",
      "episode_reward_mean: 132.1135938390129\n",
      "episode_reward_min: -5065.875783868027\n",
      "episodes_this_iter: 181\n",
      "episodes_total: 888\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 357.8576354980469\n",
      "        policy_entropy: 22.06981658935547\n",
      "        policy_loss: 77.01089477539062\n",
      "        vf_loss: 89.2016372680664\n",
      "  num_steps_sampled: 88830\n",
      "  num_steps_trained: 88830\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 6\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 94.8142857142857\n",
      "  ram_util_percent: 89.77142857142857\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.037429353629849754\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06796986296625315\n",
      "  mean_inference_ms: 1.0714413257438622\n",
      "  mean_raw_obs_processing_ms: 0.1084080780648644\n",
      "time_since_restore: 25.00445294380188\n",
      "time_this_iter_s: 4.986119985580444\n",
      "time_total_s: 25.00445294380188\n",
      "timers:\n",
      "  apply_grad_throughput: 11614.388\n",
      "  apply_grad_time_ms: 0.861\n",
      "  grad_wait_time_ms: 1.013\n",
      "  update_time_ms: 0.67\n",
      "timestamp: 1641332208\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 88830\n",
      "training_iteration: 6\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-36-53\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 2471.486454030368\n",
      "episode_reward_mean: -85.40240987582474\n",
      "episode_reward_min: -25904.916338885003\n",
      "episodes_this_iter: 184\n",
      "episodes_total: 1072\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 332.3525390625\n",
      "        policy_entropy: 13.002667427062988\n",
      "        policy_loss: 49.2509880065918\n",
      "        vf_loss: 86.9371109008789\n",
      "  num_steps_sampled: 106770\n",
      "  num_steps_trained: 106770\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 7\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 94.91428571428573\n",
      "  ram_util_percent: 89.77142857142857\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.037442425530072466\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06797480230251676\n",
      "  mean_inference_ms: 1.0697034025423346\n",
      "  mean_raw_obs_processing_ms: 0.10831891398110498\n",
      "time_since_restore: 29.993293046951294\n",
      "time_this_iter_s: 4.988840103149414\n",
      "time_total_s: 29.993293046951294\n",
      "timers:\n",
      "  apply_grad_throughput: 10680.139\n",
      "  apply_grad_time_ms: 0.936\n",
      "  grad_wait_time_ms: 1.029\n",
      "  update_time_ms: 0.815\n",
      "timestamp: 1641332213\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 106770\n",
      "training_iteration: 7\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-36-58\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 833.3089078509946\n",
      "episode_reward_mean: 170.0013669845019\n",
      "episode_reward_min: 83.00609683182319\n",
      "episodes_this_iter: 169\n",
      "episodes_total: 1241\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 190.17567443847656\n",
      "        policy_entropy: 8.29339599609375\n",
      "        policy_loss: 42.49174118041992\n",
      "        vf_loss: 48.8682861328125\n",
      "  num_steps_sampled: 124180\n",
      "  num_steps_trained: 124180\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 8\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 94.61428571428573\n",
      "  ram_util_percent: 89.87142857142858\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03751328992963228\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06814322442059029\n",
      "  mean_inference_ms: 1.0724364525418106\n",
      "  mean_raw_obs_processing_ms: 0.10851145266455921\n",
      "time_since_restore: 34.98147201538086\n",
      "time_this_iter_s: 4.988178968429565\n",
      "time_total_s: 34.98147201538086\n",
      "timers:\n",
      "  apply_grad_throughput: 11476.152\n",
      "  apply_grad_time_ms: 0.871\n",
      "  grad_wait_time_ms: 1.023\n",
      "  update_time_ms: 0.889\n",
      "timestamp: 1641332218\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 124180\n",
      "training_iteration: 8\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-37-03\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 1397.3980655789658\n",
      "episode_reward_mean: 198.55269678212466\n",
      "episode_reward_min: 83.43658106012631\n",
      "episodes_this_iter: 159\n",
      "episodes_total: 1400\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 218.80502319335938\n",
      "        policy_entropy: 17.230558395385742\n",
      "        policy_loss: 23.071897506713867\n",
      "        vf_loss: 22.735231399536133\n",
      "  num_steps_sampled: 139540\n",
      "  num_steps_trained: 139540\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 9\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 95.8125\n",
      "  ram_util_percent: 89.91250000000001\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03769888705153289\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06853084342011896\n",
      "  mean_inference_ms: 1.079905767896844\n",
      "  mean_raw_obs_processing_ms: 0.10908502240730113\n",
      "time_since_restore: 39.972163915634155\n",
      "time_this_iter_s: 4.990691900253296\n",
      "time_total_s: 39.972163915634155\n",
      "timers:\n",
      "  apply_grad_throughput: 10899.958\n",
      "  apply_grad_time_ms: 0.917\n",
      "  grad_wait_time_ms: 1.277\n",
      "  update_time_ms: 0.818\n",
      "timestamp: 1641332223\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 139540\n",
      "training_iteration: 9\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-37-08\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 522.5044477213024\n",
      "episode_reward_mean: 185.74101589894775\n",
      "episode_reward_min: 38.12171713675326\n",
      "episodes_this_iter: 168\n",
      "episodes_total: 1568\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 117.10249328613281\n",
      "        policy_entropy: 14.872689247131348\n",
      "        policy_loss: 39.33818054199219\n",
      "        vf_loss: 13.48868179321289\n",
      "  num_steps_sampled: 156790\n",
      "  num_steps_trained: 156790\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 10\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 81.22857142857143\n",
      "  ram_util_percent: 89.71428571428571\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03769364538246809\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0684794396790413\n",
      "  mean_inference_ms: 1.0798800814535667\n",
      "  mean_raw_obs_processing_ms: 0.1090566218873749\n",
      "time_since_restore: 44.962124824523926\n",
      "time_this_iter_s: 4.9899609088897705\n",
      "time_total_s: 44.962124824523926\n",
      "timers:\n",
      "  apply_grad_throughput: 13024.575\n",
      "  apply_grad_time_ms: 0.768\n",
      "  grad_wait_time_ms: 1.218\n",
      "  update_time_ms: 0.957\n",
      "timestamp: 1641332228\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 156790\n",
      "training_iteration: 10\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-37-13\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 610.8459102975651\n",
      "episode_reward_mean: 205.56306649818285\n",
      "episode_reward_min: 57.95823259366942\n",
      "episodes_this_iter: 168\n",
      "episodes_total: 1736\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 12391.33203125\n",
      "        policy_entropy: 4.234443187713623\n",
      "        policy_loss: -2209.501708984375\n",
      "        vf_loss: 93623.296875\n",
      "  num_steps_sampled: 173520\n",
      "  num_steps_trained: 173520\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 11\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 81.92857142857143\n",
      "  ram_util_percent: 89.82857142857142\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.037767560249189716\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06857428164712626\n",
      "  mean_inference_ms: 1.082001760787666\n",
      "  mean_raw_obs_processing_ms: 0.10915115574457156\n",
      "time_since_restore: 49.951589822769165\n",
      "time_this_iter_s: 4.989464998245239\n",
      "time_total_s: 49.951589822769165\n",
      "timers:\n",
      "  apply_grad_throughput: 11397.565\n",
      "  apply_grad_time_ms: 0.877\n",
      "  grad_wait_time_ms: 0.97\n",
      "  update_time_ms: 0.715\n",
      "timestamp: 1641332233\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 173520\n",
      "training_iteration: 11\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-37-18\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 421.76273266800035\n",
      "episode_reward_mean: 204.0154435886563\n",
      "episode_reward_min: 68.7190556431023\n",
      "episodes_this_iter: 176\n",
      "episodes_total: 1912\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 1259.4937744140625\n",
      "        policy_entropy: 7.564854145050049\n",
      "        policy_loss: -243.426025390625\n",
      "        vf_loss: 829.6220092773438\n",
      "  num_steps_sampled: 191020\n",
      "  num_steps_trained: 191020\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 12\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 81.64285714285714\n",
      "  ram_util_percent: 89.89999999999999\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03777999527347448\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06857342329216333\n",
      "  mean_inference_ms: 1.0815146994354068\n",
      "  mean_raw_obs_processing_ms: 0.10906512000837995\n",
      "time_since_restore: 54.94255495071411\n",
      "time_this_iter_s: 4.990965127944946\n",
      "time_total_s: 54.94255495071411\n",
      "timers:\n",
      "  apply_grad_throughput: 10756.832\n",
      "  apply_grad_time_ms: 0.93\n",
      "  grad_wait_time_ms: 1.112\n",
      "  update_time_ms: 0.811\n",
      "timestamp: 1641332238\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 191020\n",
      "training_iteration: 12\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-37-23\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 487.46849118445317\n",
      "episode_reward_mean: 226.61295468373544\n",
      "episode_reward_min: 44.683442916596945\n",
      "episodes_this_iter: 176\n",
      "episodes_total: 2088\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 1358.22021484375\n",
      "        policy_entropy: 7.5041069984436035\n",
      "        policy_loss: 148.74928283691406\n",
      "        vf_loss: 1388.8980712890625\n",
      "  num_steps_sampled: 208560\n",
      "  num_steps_trained: 208560\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 13\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 82.22857142857143\n",
      "  ram_util_percent: 89.87142857142858\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.037795750127284596\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06861534758961034\n",
      "  mean_inference_ms: 1.081440319818122\n",
      "  mean_raw_obs_processing_ms: 0.10907219944242871\n",
      "time_since_restore: 59.9309139251709\n",
      "time_this_iter_s: 4.988358974456787\n",
      "time_total_s: 59.9309139251709\n",
      "timers:\n",
      "  apply_grad_throughput: 12407.348\n",
      "  apply_grad_time_ms: 0.806\n",
      "  grad_wait_time_ms: 0.961\n",
      "  update_time_ms: 0.676\n",
      "timestamp: 1641332243\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 208560\n",
      "training_iteration: 13\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-37-28\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 617.5070710640158\n",
      "episode_reward_mean: 232.83533885937803\n",
      "episode_reward_min: 27.253401077860133\n",
      "episodes_this_iter: 176\n",
      "episodes_total: 2264\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 21765.48046875\n",
      "        policy_entropy: 11.635622024536133\n",
      "        policy_loss: -3016.47412109375\n",
      "        vf_loss: 181909.34375\n",
      "  num_steps_sampled: 226460\n",
      "  num_steps_trained: 226460\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 14\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 95.74285714285713\n",
      "  ram_util_percent: 89.95714285714287\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03776905341141063\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06861938131885353\n",
      "  mean_inference_ms: 1.0804771096052974\n",
      "  mean_raw_obs_processing_ms: 0.10905644497523587\n",
      "time_since_restore: 64.9214437007904\n",
      "time_this_iter_s: 4.990529775619507\n",
      "time_total_s: 64.9214437007904\n",
      "timers:\n",
      "  apply_grad_throughput: 12153.176\n",
      "  apply_grad_time_ms: 0.823\n",
      "  grad_wait_time_ms: 1.003\n",
      "  update_time_ms: 0.771\n",
      "timestamp: 1641332248\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 226460\n",
      "training_iteration: 14\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-37-33\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 580.3944080630818\n",
      "episode_reward_mean: -2639.7833292736204\n",
      "episode_reward_min: -472823.2845288911\n",
      "episodes_this_iter: 171\n",
      "episodes_total: 2435\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 915.7576904296875\n",
      "        policy_entropy: 6.483345031738281\n",
      "        policy_loss: 41.997039794921875\n",
      "        vf_loss: 222.59716796875\n",
      "  num_steps_sampled: 243410\n",
      "  num_steps_trained: 243410\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 15\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 95.35714285714285\n",
      "  ram_util_percent: 90.01428571428572\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.037817338887879186\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0687101099522929\n",
      "  mean_inference_ms: 1.0815551341469807\n",
      "  mean_raw_obs_processing_ms: 0.10917273106688574\n",
      "time_since_restore: 69.9131829738617\n",
      "time_this_iter_s: 4.991739273071289\n",
      "time_total_s: 69.9131829738617\n",
      "timers:\n",
      "  apply_grad_throughput: 11181.233\n",
      "  apply_grad_time_ms: 0.894\n",
      "  grad_wait_time_ms: 1.045\n",
      "  update_time_ms: 0.793\n",
      "timestamp: 1641332253\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 243410\n",
      "training_iteration: 15\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-37-38\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 585.3648617841026\n",
      "episode_reward_mean: 248.57981631066107\n",
      "episode_reward_min: 64.55968371377983\n",
      "episodes_this_iter: 181\n",
      "episodes_total: 2616\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 807.6506958007812\n",
      "        policy_entropy: 9.006442070007324\n",
      "        policy_loss: 38.950965881347656\n",
      "        vf_loss: 272.1548156738281\n",
      "  num_steps_sampled: 261600\n",
      "  num_steps_trained: 261600\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 16\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 95.0142857142857\n",
      "  ram_util_percent: 89.98571428571428\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.037797295185496155\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06864861509400169\n",
      "  mean_inference_ms: 1.080508314029589\n",
      "  mean_raw_obs_processing_ms: 0.1091067564170615\n",
      "time_since_restore: 74.89860773086548\n",
      "time_this_iter_s: 4.985424757003784\n",
      "time_total_s: 74.89860773086548\n",
      "timers:\n",
      "  apply_grad_throughput: 12995.922\n",
      "  apply_grad_time_ms: 0.769\n",
      "  grad_wait_time_ms: 1.047\n",
      "  update_time_ms: 0.734\n",
      "timestamp: 1641332258\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 261600\n",
      "training_iteration: 16\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-37-43\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 606.7412534274221\n",
      "episode_reward_mean: 252.80428966615742\n",
      "episode_reward_min: -12.85645480898126\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 2808\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 605.239501953125\n",
      "        policy_entropy: 9.150487899780273\n",
      "        policy_loss: 24.660520553588867\n",
      "        vf_loss: 47.26809310913086\n",
      "  num_steps_sampled: 280500\n",
      "  num_steps_trained: 280500\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 17\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 80.98571428571428\n",
      "  ram_util_percent: 89.88571428571427\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03771807678853715\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06850635534607862\n",
      "  mean_inference_ms: 1.077360535343189\n",
      "  mean_raw_obs_processing_ms: 0.10898177946775857\n",
      "time_since_restore: 79.88874554634094\n",
      "time_this_iter_s: 4.990137815475464\n",
      "time_total_s: 79.88874554634094\n",
      "timers:\n",
      "  apply_grad_throughput: 11885.922\n",
      "  apply_grad_time_ms: 0.841\n",
      "  grad_wait_time_ms: 0.998\n",
      "  update_time_ms: 0.684\n",
      "timestamp: 1641332263\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 280500\n",
      "training_iteration: 17\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-37-48\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 742.8358932557747\n",
      "episode_reward_mean: 270.92002064397525\n",
      "episode_reward_min: -130.76821788240116\n",
      "episodes_this_iter: 185\n",
      "episodes_total: 2993\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 488.011474609375\n",
      "        policy_entropy: 11.433018684387207\n",
      "        policy_loss: -7.226183891296387\n",
      "        vf_loss: 14.285058975219727\n",
      "  num_steps_sampled: 299370\n",
      "  num_steps_trained: 299370\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 18\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 94.975\n",
      "  ram_util_percent: 89.8\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.037686041451352466\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06842604343801507\n",
      "  mean_inference_ms: 1.074844940800883\n",
      "  mean_raw_obs_processing_ms: 0.10888625220342794\n",
      "time_since_restore: 84.87725567817688\n",
      "time_this_iter_s: 4.9885101318359375\n",
      "time_total_s: 84.87725567817688\n",
      "timers:\n",
      "  apply_grad_throughput: 12255.446\n",
      "  apply_grad_time_ms: 0.816\n",
      "  grad_wait_time_ms: 0.99\n",
      "  update_time_ms: 0.688\n",
      "timestamp: 1641332268\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 299370\n",
      "training_iteration: 18\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-37-53\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 554.3668191103751\n",
      "episode_reward_mean: 275.2326830545638\n",
      "episode_reward_min: -46.087501174321446\n",
      "episodes_this_iter: 183\n",
      "episodes_total: 3176\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 1823.8096923828125\n",
      "        policy_entropy: 5.342452526092529\n",
      "        policy_loss: 61.79533004760742\n",
      "        vf_loss: 2125.741943359375\n",
      "  num_steps_sampled: 317390\n",
      "  num_steps_trained: 317390\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 19\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 93.38571428571429\n",
      "  ram_util_percent: 89.94285714285715\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03765730472583979\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06837692467085947\n",
      "  mean_inference_ms: 1.0740256386922409\n",
      "  mean_raw_obs_processing_ms: 0.10879559166523489\n",
      "time_since_restore: 89.86734461784363\n",
      "time_this_iter_s: 4.990088939666748\n",
      "time_total_s: 89.86734461784363\n",
      "timers:\n",
      "  apply_grad_throughput: 11027.195\n",
      "  apply_grad_time_ms: 0.907\n",
      "  grad_wait_time_ms: 1.062\n",
      "  update_time_ms: 0.729\n",
      "timestamp: 1641332273\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 317390\n",
      "training_iteration: 19\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-37-58\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 988.7568998033781\n",
      "episode_reward_mean: 276.6717788124474\n",
      "episode_reward_min: -232.30382639718377\n",
      "episodes_this_iter: 188\n",
      "episodes_total: 3364\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 3611.337158203125\n",
      "        policy_entropy: 7.542189121246338\n",
      "        policy_loss: 57.864837646484375\n",
      "        vf_loss: 661.1775512695312\n",
      "  num_steps_sampled: 336210\n",
      "  num_steps_trained: 336210\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 20\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 94.25714285714287\n",
      "  ram_util_percent: 89.85714285714286\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.037613279799356136\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0682804956204868\n",
      "  mean_inference_ms: 1.07203073016444\n",
      "  mean_raw_obs_processing_ms: 0.10868777056639084\n",
      "time_since_restore: 94.8579249382019\n",
      "time_this_iter_s: 4.990580320358276\n",
      "time_total_s: 94.8579249382019\n",
      "timers:\n",
      "  apply_grad_throughput: 10159.144\n",
      "  apply_grad_time_ms: 0.984\n",
      "  grad_wait_time_ms: 1.282\n",
      "  update_time_ms: 0.913\n",
      "timestamp: 1641332278\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 336210\n",
      "training_iteration: 20\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-38-03\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 2218.502014838328\n",
      "episode_reward_mean: -1551841483.7174575\n",
      "episode_reward_min: -156062421874.71\n",
      "episodes_this_iter: 188\n",
      "episodes_total: 3552\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 132531789824.0\n",
      "        policy_entropy: 12.54809284210205\n",
      "        policy_loss: -28157693952.0\n",
      "        vf_loss: 1.8007657128814182e+18\n",
      "  num_steps_sampled: 355030\n",
      "  num_steps_trained: 355030\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 21\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 94.39999999999999\n",
      "  ram_util_percent: 89.77142857142859\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.037567645092115645\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06819284159879205\n",
      "  mean_inference_ms: 1.070271878192721\n",
      "  mean_raw_obs_processing_ms: 0.10859295658323544\n",
      "time_since_restore: 99.84508109092712\n",
      "time_this_iter_s: 4.98715615272522\n",
      "time_total_s: 99.84508109092712\n",
      "timers:\n",
      "  apply_grad_throughput: 12217.25\n",
      "  apply_grad_time_ms: 0.819\n",
      "  grad_wait_time_ms: 0.97\n",
      "  update_time_ms: 0.72\n",
      "timestamp: 1641332283\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 355030\n",
      "training_iteration: 21\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-38-08\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 2651.8550758181223\n",
      "episode_reward_mean: -2.7528701848921702e+20\n",
      "episode_reward_min: -4.468642204033332e+22\n",
      "episodes_this_iter: 184\n",
      "episodes_total: 3736\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 154.12400817871094\n",
      "        policy_entropy: 11.468009948730469\n",
      "        policy_loss: 36.22092819213867\n",
      "        vf_loss: 18.182842254638672\n",
      "  num_steps_sampled: 373730\n",
      "  num_steps_trained: 373730\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 22\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 93.74285714285713\n",
      "  ram_util_percent: 89.72857142857143\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03751451456478868\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06808695923007839\n",
      "  mean_inference_ms: 1.0684697774745153\n",
      "  mean_raw_obs_processing_ms: 0.10846406759475091\n",
      "time_since_restore: 104.83250522613525\n",
      "time_this_iter_s: 4.98742413520813\n",
      "time_total_s: 104.83250522613525\n",
      "timers:\n",
      "  apply_grad_throughput: 12290.641\n",
      "  apply_grad_time_ms: 0.814\n",
      "  grad_wait_time_ms: 0.902\n",
      "  update_time_ms: 0.672\n",
      "timestamp: 1641332288\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 373730\n",
      "training_iteration: 22\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-38-13\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 7567.262718862384\n",
      "episode_reward_mean: -2165.194923109519\n",
      "episode_reward_min: -157723.31280747417\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 3928\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 429.7904357910156\n",
      "        policy_entropy: 12.21223258972168\n",
      "        policy_loss: -4.718214511871338\n",
      "        vf_loss: 22.997175216674805\n",
      "  num_steps_sampled: 392400\n",
      "  num_steps_trained: 392400\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 23\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 80.62857142857142\n",
      "  ram_util_percent: 89.6857142857143\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.037472883678539536\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06800196404410427\n",
      "  mean_inference_ms: 1.0668944017884583\n",
      "  mean_raw_obs_processing_ms: 0.10835920696153152\n",
      "time_since_restore: 109.81917929649353\n",
      "time_this_iter_s: 4.986674070358276\n",
      "time_total_s: 109.81917929649353\n",
      "timers:\n",
      "  apply_grad_throughput: 11346.076\n",
      "  apply_grad_time_ms: 0.881\n",
      "  grad_wait_time_ms: 0.999\n",
      "  update_time_ms: 0.708\n",
      "timestamp: 1641332293\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 392400\n",
      "training_iteration: 23\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-38-18\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 3552.1132940102784\n",
      "episode_reward_mean: -878952.5352193564\n",
      "episode_reward_min: -129041734.73091379\n",
      "episodes_this_iter: 184\n",
      "episodes_total: 4112\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 889.6038208007812\n",
      "        policy_entropy: 10.815874099731445\n",
      "        policy_loss: 26.103055953979492\n",
      "        vf_loss: 161.7976531982422\n",
      "  num_steps_sampled: 410840\n",
      "  num_steps_trained: 410840\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 24\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 80.38571428571429\n",
      "  ram_util_percent: 89.74285714285713\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03744391690567931\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06795356634895841\n",
      "  mean_inference_ms: 1.0660758233753613\n",
      "  mean_raw_obs_processing_ms: 0.10827447198585462\n",
      "time_since_restore: 114.80863308906555\n",
      "time_this_iter_s: 4.9894537925720215\n",
      "time_total_s: 114.80863308906555\n",
      "timers:\n",
      "  apply_grad_throughput: 10305.162\n",
      "  apply_grad_time_ms: 0.97\n",
      "  grad_wait_time_ms: 1.025\n",
      "  update_time_ms: 0.81\n",
      "timestamp: 1641332298\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 410840\n",
      "training_iteration: 24\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-38-23\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 2063.4618507772298\n",
      "episode_reward_mean: -35731.34159285793\n",
      "episode_reward_min: -6375435.598763607\n",
      "episodes_this_iter: 184\n",
      "episodes_total: 4296\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 11360.3896484375\n",
      "        policy_entropy: 5.259283065795898\n",
      "        policy_loss: 293.64422607421875\n",
      "        vf_loss: 5924.6572265625\n",
      "  num_steps_sampled: 429210\n",
      "  num_steps_trained: 429210\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 25\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 95.25714285714285\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.037428740122719996\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06791979888738088\n",
      "  mean_inference_ms: 1.0654316846811747\n",
      "  mean_raw_obs_processing_ms: 0.10823913351008527\n",
      "time_since_restore: 119.7953712940216\n",
      "time_this_iter_s: 4.986738204956055\n",
      "time_total_s: 119.7953712940216\n",
      "timers:\n",
      "  apply_grad_throughput: 11478.35\n",
      "  apply_grad_time_ms: 0.871\n",
      "  grad_wait_time_ms: 1.074\n",
      "  update_time_ms: 0.828\n",
      "timestamp: 1641332303\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 429210\n",
      "training_iteration: 25\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-38-28\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 4647.525800252088\n",
      "episode_reward_mean: -22999.6557617621\n",
      "episode_reward_min: -3934033.0616461677\n",
      "episodes_this_iter: 176\n",
      "episodes_total: 4472\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 2873.872314453125\n",
      "        policy_entropy: 6.2055816650390625\n",
      "        policy_loss: 65.33937072753906\n",
      "        vf_loss: 1270.614990234375\n",
      "  num_steps_sampled: 447300\n",
      "  num_steps_trained: 447300\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 26\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 95.05714285714285\n",
      "  ram_util_percent: 89.89999999999999\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03742600579516115\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06790946362905287\n",
      "  mean_inference_ms: 1.0652137826168515\n",
      "  mean_raw_obs_processing_ms: 0.10824843734629569\n",
      "time_since_restore: 124.78065013885498\n",
      "time_this_iter_s: 4.985278844833374\n",
      "time_total_s: 124.78065013885498\n",
      "timers:\n",
      "  apply_grad_throughput: 12244.713\n",
      "  apply_grad_time_ms: 0.817\n",
      "  grad_wait_time_ms: 1.031\n",
      "  update_time_ms: 0.647\n",
      "timestamp: 1641332308\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 447300\n",
      "training_iteration: 26\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-38-33\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 3672.61026532036\n",
      "episode_reward_mean: -15021.156445384946\n",
      "episode_reward_min: -1496084.3349101834\n",
      "episodes_this_iter: 184\n",
      "episodes_total: 4656\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 478172.96875\n",
      "        policy_entropy: 9.536096572875977\n",
      "        policy_loss: -1371.55517578125\n",
      "        vf_loss: 63488.609375\n",
      "  num_steps_sampled: 465550\n",
      "  num_steps_trained: 465550\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 27\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 94.2875\n",
      "  ram_util_percent: 89.95\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03742299741563953\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06791773728588801\n",
      "  mean_inference_ms: 1.0648596157967039\n",
      "  mean_raw_obs_processing_ms: 0.10823271609005101\n",
      "time_since_restore: 129.76859402656555\n",
      "time_this_iter_s: 4.987943887710571\n",
      "time_total_s: 129.76859402656555\n",
      "timers:\n",
      "  apply_grad_throughput: 12699.622\n",
      "  apply_grad_time_ms: 0.787\n",
      "  grad_wait_time_ms: 0.924\n",
      "  update_time_ms: 0.692\n",
      "timestamp: 1641332313\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 465550\n",
      "training_iteration: 27\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-38-38\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 2120.6562578472917\n",
      "episode_reward_mean: 277.3207643161691\n",
      "episode_reward_min: -469.23529492549153\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 4848\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 1498.878173828125\n",
      "        policy_entropy: 14.913277626037598\n",
      "        policy_loss: -12.648798942565918\n",
      "        vf_loss: 55.213321685791016\n",
      "  num_steps_sampled: 484420\n",
      "  num_steps_trained: 484420\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 28\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 94.35714285714286\n",
      "  ram_util_percent: 89.95714285714284\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03739438040035844\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06786536168328466\n",
      "  mean_inference_ms: 1.0637093514977394\n",
      "  mean_raw_obs_processing_ms: 0.1081480092177004\n",
      "time_since_restore: 134.75736498832703\n",
      "time_this_iter_s: 4.988770961761475\n",
      "time_total_s: 134.75736498832703\n",
      "timers:\n",
      "  apply_grad_throughput: 12510.601\n",
      "  apply_grad_time_ms: 0.799\n",
      "  grad_wait_time_ms: 0.958\n",
      "  update_time_ms: 0.745\n",
      "timestamp: 1641332318\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 484420\n",
      "training_iteration: 28\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-38-43\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 3996.5006755088316\n",
      "episode_reward_mean: -7.570540222818683e+20\n",
      "episode_reward_min: -1.1160732498726211e+23\n",
      "episodes_this_iter: 184\n",
      "episodes_total: 5032\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 3600.168212890625\n",
      "        policy_entropy: 0.4578542113304138\n",
      "        policy_loss: -59.08689498901367\n",
      "        vf_loss: 1331.058837890625\n",
      "  num_steps_sampled: 502890\n",
      "  num_steps_trained: 502890\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 29\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 80.41428571428571\n",
      "  ram_util_percent: 89.87142857142858\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03737537143982953\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06783303336368192\n",
      "  mean_inference_ms: 1.0629558498105651\n",
      "  mean_raw_obs_processing_ms: 0.10810487706242522\n",
      "time_since_restore: 139.74653005599976\n",
      "time_this_iter_s: 4.9891650676727295\n",
      "time_total_s: 139.74653005599976\n",
      "timers:\n",
      "  apply_grad_throughput: 11265.018\n",
      "  apply_grad_time_ms: 0.888\n",
      "  grad_wait_time_ms: 0.953\n",
      "  update_time_ms: 0.807\n",
      "timestamp: 1641332323\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 502890\n",
      "training_iteration: 29\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-38-48\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 886.3548510551835\n",
      "episode_reward_mean: -8132178220.06704\n",
      "episode_reward_min: -660396751933.4614\n",
      "episodes_this_iter: 181\n",
      "episodes_total: 5213\n",
      "experiment_id: de2a1ccd1b864b29851daafb55a4f949\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 863.3211059570312\n",
      "        policy_entropy: 5.925908088684082\n",
      "        policy_loss: 23.7379207611084\n",
      "        vf_loss: 218.3837432861328\n",
      "  num_steps_sampled: 521080\n",
      "  num_steps_trained: 521080\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 30\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 93.57142857142857\n",
      "  ram_util_percent: 89.98571428571428\n",
      "pid: 48860\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.037360970550250054\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06781857097962919\n",
      "  mean_inference_ms: 1.0625081359971371\n",
      "  mean_raw_obs_processing_ms: 0.10807788363833423\n",
      "time_since_restore: 144.73360109329224\n",
      "time_this_iter_s: 4.9870710372924805\n",
      "time_total_s: 144.73360109329224\n",
      "timers:\n",
      "  apply_grad_throughput: 12544.651\n",
      "  apply_grad_time_ms: 0.797\n",
      "  grad_wait_time_ms: 0.922\n",
      "  update_time_ms: 0.722\n",
      "timestamp: 1641332328\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 521080\n",
      "training_iteration: 30\n",
      "trial_id: default\n",
      "\n",
      "checkpoint saved at /Users/mingweima/ray_results/A3C_my-env_2022-01-04_15-36-21r1vf5nki/checkpoint_000030/checkpoint-30\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()\n",
    "env = WhitedBasicModel(env_config={\"structural_params\": {\"gamma\": [0.9,0.96],\n",
    "                                                         \"delta\": [0.1, 0.3],\n",
    "                                                         \"theta\": [0.5, 0.8],\n",
    "                                                         \"rho\": [0.3, 0.8],\n",
    "                                                         \"sigma\": [0., 0.15],\n",
    "                                                        }, \n",
    "                                   \"env_params\": {\"psi_func\": lambda i, k: 0.01*i**2/(2*k)\n",
    "                                                 },\n",
    "                                   \"is_mutable\": True,\n",
    "                                  })\n",
    "solver = RaySolver(env=env,\n",
    "                   trainer=A3C_Trainer,\n",
    "                   solver_params={\"verbose\": True, \"episodes\": 30,\n",
    "                                  \"trainer_config\": {\n",
    "                                      \"num_workers\": 8,\n",
    "                                      \"gamma\": env.current_structural_params.get(\"gamma\", 0.99),\n",
    "                                  }\n",
    "                                  })\n",
    "solver.train()\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mingweima/ray_results/A3C_my-env_2022-01-04_15-11-160hhhuamk/checkpoint_000030/checkpoint-30'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.26595008e+00 9.99950588e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 0.5780609418282548 False {}\n",
      "[1.60262966e+00 9.99243736e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 0.6342507175787155 False {}\n",
      "[2.02884912e+00 9.99478579e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 0.688059452734865 False {}\n",
      "[2.56842184e+00 9.99123633e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 0.7384236772045981 False {}\n",
      "[2.57559347e+00 9.99628723e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 1.45656105511421 False {}\n",
      "[3.26057267e+00 1.00016975e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 0.7800528580714188 False {}\n",
      "[3.26967692e+00 1.00030673e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 1.6672278643701115 False {}\n",
      "[3.27880645e+00 9.99853015e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 1.6701099085750295 False {}\n",
      "[3.28796148e+00 1.00032210e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 1.671702730237031 False {}\n",
      "[3.29714203e+00 1.00061333e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 1.67532007400029 False {}\n",
      "[3.30634832e+00 1.00070512e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 1.6785536150899132 False {}\n",
      "[3.31558037e+00 9.99877214e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 1.6813537343748848 False {}\n",
      "[4.19735909e+00 9.99952853e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 0.8070819903644646 False {}\n",
      "[5.31364727e+00 1.00091815e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 0.8068569816481681 False {}\n",
      "[6.72681236e+00 1.00032496e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 0.773035806746198 False {}\n",
      "[6.74559498e+00 1.00084376e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 2.4579421582532888 False {}\n",
      "[6.76443005e+00 1.00070226e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 2.4632908924001478 False {}\n",
      "[6.78331757e+00 1.00084198e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 2.4663173609760856 False {}\n",
      "[6.80225801e+00 1.00084889e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 2.4703409233354225 False {}\n",
      "[6.82125139e+00 1.00006938e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 2.4738991352458806 False {}\n",
      "[6.84029770e+00 1.00084531e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 2.4746674925667307 False {}\n",
      "[8.65947533e+00 1.00102115e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 0.6756757962070576 False {}\n",
      "[1.09624634e+01 1.00034797e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 0.5088645318215419 False {}\n",
      "[1.09930725e+01 9.99498665e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.128329552809042 False {}\n",
      "[1.10237675e+01 9.99555647e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.128314081621168 False {}\n",
      "[1.10545483e+01 9.99480128e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.132706246448114 False {}\n",
      "[1.10854149e+01 9.98936474e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.1364550484549927 False {}\n",
      "[1.11163673e+01 1.00031185e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.1379140023774443 False {}\n",
      "[1.11474066e+01 1.00046802e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.1487767010199894 False {}\n",
      "[1.11785326e+01 9.99818146e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.1536773915944147 False {}\n",
      "[1.12097454e+01 9.99570906e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.154616636495853 False {}\n",
      "[1.41909781e+01 1.00050342e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 0.19906011668325174 False {}\n",
      "[1.42306023e+01 1.00179923e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.522144445169292 False {}\n",
      "[1.42703371e+01 1.00072563e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.533984243855698 False {}\n",
      "[1.43101826e+01 1.00028110e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.532151558827679 False {}\n",
      "[1.43501396e+01 9.99731839e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.533942624768496 False {}\n",
      "[1.43902082e+01 9.99978244e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.5351184464487546 False {}\n",
      "[1.44303885e+01 1.00003135e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.54091131831445 False {}\n",
      "[1.44706812e+01 9.99542713e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.5455853658333054 False {}\n",
      "[1.45110865e+01 9.99943793e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.547100743102299 False {}\n",
      "[1.45516043e+01 9.99969244e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.553809951042451 False {}\n",
      "[1.45922356e+01 1.00055254e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.5583293364578763 False {}\n",
      "[1.46329803e+01 1.00029159e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.566125097554214 False {}\n",
      "[1.46738386e+01 1.00009179e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.5689716821919566 False {}\n",
      "[1.31701965e+01 9.99964476e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 1 5.1184152641261145 False {}\n",
      "[1.66728115e+01 1.00073504e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 -0.07259364789864264 False {}\n",
      "[1.67193661e+01 1.00048244e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.7786562349479214 False {}\n",
      "[1.67660503e+01 1.00087917e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 3.7814946642525897 False {}\n",
      "[2.12249832e+01 1.00045097e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 -0.6363854644080531 False {}\n",
      "[2.12842484e+01 1.00089025e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.165226271119724 False {}\n",
      "[2.69447956e+01 1.00107312e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 -1.4443084538541555 False {}\n",
      "[2.70200310e+01 1.00021899e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.549745809552465 False {}\n",
      "[2.70954762e+01 1.00054312e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.546556625479504 False {}\n",
      "[2.71711311e+01 9.99901116e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.553741119498207 False {}\n",
      "[3.43972969e+01 1.00037718e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 -2.6186103414724347 False {}\n",
      "[3.44933395e+01 1.00145173e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.905641362446749 False {}\n",
      "[3.45896530e+01 1.00070977e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.920646393261521 False {}\n",
      "[3.46862335e+01 1.00048339e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.916838403483653 False {}\n",
      "[3.47830849e+01 9.99807119e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.918353844281727 False {}\n",
      "[3.48802071e+01 1.00020742e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.915168268792908 False {}\n",
      "[4.41566010e+01 1.00054193e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 -4.282391625555773 False {}\n",
      "[4.42798958e+01 1.00021958e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.219300265739872 False {}\n",
      "[4.44035339e+01 1.00002980e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.21835374024474 False {}\n",
      "[5.62126579e+01 1.00011873e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 -6.499964309569908 False {}\n",
      "[5.63696136e+01 9.99580801e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.415442602259173 False {}\n",
      "[5.65270081e+01 1.00006843e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.409280212561933 False {}\n",
      "[5.66848412e+01 1.00080597e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.417784618219841 False {}\n",
      "[5.68431168e+01 9.99917388e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.429886741886335 False {}\n",
      "[5.70018349e+01 1.00021672e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.41858730090566 False {}\n",
      "[5.71609955e+01 1.00051534e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.424359777709993 False {}\n",
      "[5.73205986e+01 1.00092626e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.4301166843930595 False {}\n",
      "[5.74806480e+01 1.00134432e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.437494490900132 False {}\n",
      "[5.76411438e+01 1.00117493e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.4449766833079405 False {}\n",
      "[5.78020897e+01 1.00088000e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.443920880510051 False {}\n",
      "[5.79634857e+01 1.00104284e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.441006592520264 False {}\n",
      "[5.81253319e+01 1.00061893e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.4447331315018275 False {}\n",
      "[5.82876282e+01 9.99951184e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.439870922727655 False {}\n",
      "[5.84503784e+01 9.99440849e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.4313935273019425 False {}\n",
      "[5.86135826e+01 9.98467505e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.425167385226823 False {}\n",
      "[5.87772446e+01 9.99319792e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.41208685149485 False {}\n",
      "[5.89413605e+01 9.99985397e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.425811550697752 False {}\n",
      "[5.91059380e+01 9.99727488e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.436806353442229 False {}\n",
      "[5.92709732e+01 9.99749303e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.434167131823543 False {}\n",
      "[5.94364700e+01 9.99710441e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.435632723233569 False {}\n",
      "[5.96024284e+01 1.00044858e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.436176844046836 False {}\n",
      "[5.97688484e+01 9.99835551e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.448242311976204 False {}\n",
      "[5.99357338e+01 9.99770343e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.4402099226698475 False {}\n",
      "[6.01030846e+01 1.00044620e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.440291627156569 False {}\n",
      "[6.02709045e+01 1.00117993e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.4514197813634375 False {}\n",
      "[7.62999573e+01 1.00057256e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 -10.443248757431856 False {}\n",
      "[9.65919342e+01 1.00108409e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 -14.692344991384076 False {}\n",
      "[9.68616409e+01 1.00050199e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.196999391270889 False {}\n",
      "[9.71320953e+01 1.00081503e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 5.180160505150468 False {}\n",
      "[1.22964386e+02 1.00018895e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 8 -20.453479436727342 False {}\n",
      "[1.23307724e+02 9.99532461e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.543169316210296 False {}\n",
      "[1.23652023e+02 9.99318779e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.517322652246488 False {}\n",
      "[1.23997284e+02 1.00076222e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.502000584034782 False {}\n",
      "[1.24343506e+02 9.99794781e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.52652947418219 False {}\n",
      "[1.24690697e+02 1.00073636e+00 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.492901304746564 False {}\n",
      "[1.25038857e+02 9.99655604e-01 9.46304286e-01 1.55102543e-01\n",
      " 6.60192725e-01 6.19160279e-01 4.91249208e-04] 3 4.50529721540083 True {}\n"
     ]
    }
   ],
   "source": [
    "# run until episode ends\n",
    "episode_reward = 0\n",
    "done = False\n",
    "obs = env.reset()\n",
    "while not done:\n",
    "    action = solver.act(obs)\n",
    "    obs, reward, done, info = env.step(action, resample_param=False)\n",
    "    episode_reward += reward\n",
    "    print(obs, action, reward, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test trained agent for a single episode. Return the episode reward\"\"\"\n",
    "cp = []\n",
    "for eps in range(2):\n",
    "      # instantiate env class\n",
    "      episode_reward = 0\n",
    "      done = False\n",
    "      obs = env.reset()\n",
    "      # run until episode ends\n",
    "      caps = []\n",
    "      while not done:\n",
    "          action = solver.trainer.compute_single_action(obs, clip_action=True)\n",
    "          obs, reward, done, info = env.step(action, resample_param=False)\n",
    "          episode_reward += reward\n",
    "          #print(action, obs, reward, done)\n",
    "          caps += [obs[0]]\n",
    "      cp += [ [caps] ]\n",
    "cp = np.squeeze(np.array(cp)).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(cp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}