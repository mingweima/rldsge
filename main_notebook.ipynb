{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import gym\n",
    "import ray\n",
    "from ray.rllib.agents import ppo, a3c, cql, ddpg, dqn\n",
    "\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from source.envs.env import WhitedBasicModel\n",
    "from source.solvers.ray_solver import RaySolver\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "A3C_Trainer = a3c.A3CTrainer\n",
    "PPO_Trainer = ppo.PPOTrainer\n",
    "DQNTrainer = dqn.DQNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 15:11:15,240\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2022-01-04 15:11:17,755\tWARNING util.py:57 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=47965)\u001b[0m 2022-01-04 15:11:17,730\tWARNING deprecation.py:46 -- DeprecationWarning: `convert_to_non_torch_type` has been deprecated. Use `ray/rllib/utils/numpy.py::convert_to_numpy` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-11-17\n",
      "done: false\n",
      "episode_len_mean: .nan\n",
      "episode_media: {}\n",
      "episode_reward_max: .nan\n",
      "episode_reward_mean: .nan\n",
      "episode_reward_min: .nan\n",
      "episodes_this_iter: 0\n",
      "episodes_total: 0\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 274.0985107421875\n",
      "        policy_entropy: 29.957210540771484\n",
      "        policy_loss: 166.61790466308594\n",
      "        vf_loss: 192.6852264404297\n",
      "  num_steps_sampled: 10\n",
      "  num_steps_trained: 10\n",
      "iterations_since_restore: 1\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 92.8\n",
      "  ram_util_percent: 89.9\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf: {}\n",
      "time_since_restore: 0.11686396598815918\n",
      "time_this_iter_s: 0.11686396598815918\n",
      "time_total_s: 0.11686396598815918\n",
      "timers:\n",
      "  apply_grad_throughput: 8440.942\n",
      "  apply_grad_time_ms: 1.185\n",
      "  grad_wait_time_ms: 106.978\n",
      "  update_time_ms: 1.245\n",
      "timestamp: 1641330677\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 10\n",
      "training_iteration: 1\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-11-22\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 1558.477968645099\n",
      "episode_reward_mean: -485670221213.1092\n",
      "episode_reward_min: -44960377922099.3\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 192\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 80.98311614990234\n",
      "        policy_entropy: 22.603191375732422\n",
      "        policy_loss: 22.29573631286621\n",
      "        vf_loss: 4.606069087982178\n",
      "  num_steps_sampled: 19020\n",
      "  num_steps_trained: 19020\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 2\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 77.61428571428573\n",
      "  ram_util_percent: 89.85714285714285\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036520543720929936\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0654067791989922\n",
      "  mean_inference_ms: 1.03051521098088\n",
      "  mean_raw_obs_processing_ms: 0.10875935374754349\n",
      "time_since_restore: 5.108861923217773\n",
      "time_this_iter_s: 4.991997957229614\n",
      "time_total_s: 5.108861923217773\n",
      "timers:\n",
      "  apply_grad_throughput: 12725.051\n",
      "  apply_grad_time_ms: 0.786\n",
      "  grad_wait_time_ms: 0.977\n",
      "  update_time_ms: 0.695\n",
      "timestamp: 1641330682\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 19020\n",
      "training_iteration: 2\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-11-27\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 1996.8179117842537\n",
      "episode_reward_mean: -45382.99208871944\n",
      "episode_reward_min: -5676626.234638468\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 384\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 497.35296630859375\n",
      "        policy_entropy: 20.91576385498047\n",
      "        policy_loss: 146.87940979003906\n",
      "        vf_loss: 160.73289489746094\n",
      "  num_steps_sampled: 38290\n",
      "  num_steps_trained: 38290\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 3\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 90.52857142857144\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03646107712073018\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06528416621013751\n",
      "  mean_inference_ms: 1.0233354253784788\n",
      "  mean_raw_obs_processing_ms: 0.1068827523775147\n",
      "time_since_restore: 10.095813989639282\n",
      "time_this_iter_s: 4.986952066421509\n",
      "time_total_s: 10.095813989639282\n",
      "timers:\n",
      "  apply_grad_throughput: 12795.705\n",
      "  apply_grad_time_ms: 0.782\n",
      "  grad_wait_time_ms: 0.942\n",
      "  update_time_ms: 0.678\n",
      "timestamp: 1641330687\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 38290\n",
      "training_iteration: 3\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-11-32\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 2874.0543866105204\n",
      "episode_reward_mean: -4722.90241518627\n",
      "episode_reward_min: -700191.7247344323\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 576\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 1781.35595703125\n",
      "        policy_entropy: 13.63393783569336\n",
      "        policy_loss: 269.0342102050781\n",
      "        vf_loss: 2999.271728515625\n",
      "  num_steps_sampled: 57470\n",
      "  num_steps_trained: 57470\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 4\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 50.92857142857143\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03645271518160865\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06523777430367884\n",
      "  mean_inference_ms: 1.0213118608337555\n",
      "  mean_raw_obs_processing_ms: 0.10646218546156554\n",
      "time_since_restore: 15.084174871444702\n",
      "time_this_iter_s: 4.98836088180542\n",
      "time_total_s: 15.084174871444702\n",
      "timers:\n",
      "  apply_grad_throughput: 11516.802\n",
      "  apply_grad_time_ms: 0.868\n",
      "  grad_wait_time_ms: 0.909\n",
      "  update_time_ms: 0.666\n",
      "timestamp: 1641330692\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 57470\n",
      "training_iteration: 4\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-11-37\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 931.1863567184681\n",
      "episode_reward_mean: -38.52485988858504\n",
      "episode_reward_min: -15658.562542711463\n",
      "episodes_this_iter: 199\n",
      "episodes_total: 775\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 37.576351165771484\n",
      "        policy_entropy: 15.876273155212402\n",
      "        policy_loss: -0.6568697094917297\n",
      "        vf_loss: 1.3542065620422363\n",
      "  num_steps_sampled: 77110\n",
      "  num_steps_trained: 77110\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 5\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 77.95714285714287\n",
      "  ram_util_percent: 89.74285714285715\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03637425703611707\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06507187168024567\n",
      "  mean_inference_ms: 1.0177826215986165\n",
      "  mean_raw_obs_processing_ms: 0.10600086128894848\n",
      "time_since_restore: 20.071780920028687\n",
      "time_this_iter_s: 4.987606048583984\n",
      "time_total_s: 20.071780920028687\n",
      "timers:\n",
      "  apply_grad_throughput: 13054.98\n",
      "  apply_grad_time_ms: 0.766\n",
      "  grad_wait_time_ms: 0.902\n",
      "  update_time_ms: 0.67\n",
      "timestamp: 1641330697\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 77110\n",
      "training_iteration: 5\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-11-42\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 1853.1675238652986\n",
      "episode_reward_mean: -6.225582769121242\n",
      "episode_reward_min: -33803.083843222616\n",
      "episodes_this_iter: 193\n",
      "episodes_total: 968\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 37.89678192138672\n",
      "        policy_entropy: 13.404105186462402\n",
      "        policy_loss: 13.628593444824219\n",
      "        vf_loss: 1.5858051776885986\n",
      "  num_steps_sampled: 96640\n",
      "  num_steps_trained: 96640\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 6\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 76.92857142857143\n",
      "  ram_util_percent: 89.71428571428571\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03629590064485696\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06494785289319945\n",
      "  mean_inference_ms: 1.0146260572273518\n",
      "  mean_raw_obs_processing_ms: 0.10568587508636487\n",
      "time_since_restore: 25.058758020401\n",
      "time_this_iter_s: 4.9869771003723145\n",
      "time_total_s: 25.058758020401\n",
      "timers:\n",
      "  apply_grad_throughput: 11822.601\n",
      "  apply_grad_time_ms: 0.846\n",
      "  grad_wait_time_ms: 0.994\n",
      "  update_time_ms: 0.651\n",
      "timestamp: 1641330702\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 96640\n",
      "training_iteration: 6\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-11-47\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 1276.9501287813707\n",
      "episode_reward_mean: 169.4699734656153\n",
      "episode_reward_min: -1301.77387832064\n",
      "episodes_this_iter: 194\n",
      "episodes_total: 1162\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 345.3601379394531\n",
      "        policy_entropy: 10.084148406982422\n",
      "        policy_loss: 6.896274566650391\n",
      "        vf_loss: 90.92193603515625\n",
      "  num_steps_sampled: 116200\n",
      "  num_steps_trained: 116200\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 7\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 66.38571428571429\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03628080430927734\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06493304889700104\n",
      "  mean_inference_ms: 1.0131939925834583\n",
      "  mean_raw_obs_processing_ms: 0.10556749718811965\n",
      "time_since_restore: 30.046855926513672\n",
      "time_this_iter_s: 4.988097906112671\n",
      "time_total_s: 30.046855926513672\n",
      "timers:\n",
      "  apply_grad_throughput: 12191.681\n",
      "  apply_grad_time_ms: 0.82\n",
      "  grad_wait_time_ms: 0.879\n",
      "  update_time_ms: 0.667\n",
      "timestamp: 1641330707\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 116200\n",
      "training_iteration: 7\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-11-52\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 1270.6254068259677\n",
      "episode_reward_mean: 187.1518033909236\n",
      "episode_reward_min: -145.3436052600547\n",
      "episodes_this_iter: 198\n",
      "episodes_total: 1360\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 208.79507446289062\n",
      "        policy_entropy: 9.77145004272461\n",
      "        policy_loss: 23.687450408935547\n",
      "        vf_loss: 33.889808654785156\n",
      "  num_steps_sampled: 135580\n",
      "  num_steps_trained: 135580\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 8\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.5375\n",
      "  ram_util_percent: 89.76249999999999\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0363071606796416\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06491841040254136\n",
      "  mean_inference_ms: 1.0136391109914262\n",
      "  mean_raw_obs_processing_ms: 0.1055483690181904\n",
      "time_since_restore: 35.03486204147339\n",
      "time_this_iter_s: 4.988006114959717\n",
      "time_total_s: 35.03486204147339\n",
      "timers:\n",
      "  apply_grad_throughput: 12208.36\n",
      "  apply_grad_time_ms: 0.819\n",
      "  grad_wait_time_ms: 1.023\n",
      "  update_time_ms: 0.679\n",
      "timestamp: 1641330712\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 135580\n",
      "training_iteration: 8\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-11-57\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 658.6652917198504\n",
      "episode_reward_mean: 197.79380161816707\n",
      "episode_reward_min: 69.99344453242293\n",
      "episodes_this_iter: 195\n",
      "episodes_total: 1555\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 349.586669921875\n",
      "        policy_entropy: 5.946525573730469\n",
      "        policy_loss: 6.948426246643066\n",
      "        vf_loss: 156.72373962402344\n",
      "  num_steps_sampled: 155430\n",
      "  num_steps_trained: 155430\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 9\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 75.97142857142858\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036284368065660634\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06486334459655747\n",
      "  mean_inference_ms: 1.012589369709339\n",
      "  mean_raw_obs_processing_ms: 0.10541579143270584\n",
      "time_since_restore: 40.02321004867554\n",
      "time_this_iter_s: 4.988348007202148\n",
      "time_total_s: 40.02321004867554\n",
      "timers:\n",
      "  apply_grad_throughput: 12179.998\n",
      "  apply_grad_time_ms: 0.821\n",
      "  grad_wait_time_ms: 0.861\n",
      "  update_time_ms: 0.672\n",
      "timestamp: 1641330717\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 155430\n",
      "training_iteration: 9\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-12-02\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 612.6868286850873\n",
      "episode_reward_mean: 120.71241185086615\n",
      "episode_reward_min: -17551.574146341183\n",
      "episodes_this_iter: 197\n",
      "episodes_total: 1752\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 541.296142578125\n",
      "        policy_entropy: 8.426997184753418\n",
      "        policy_loss: 71.33123016357422\n",
      "        vf_loss: 257.66546630859375\n",
      "  num_steps_sampled: 175240\n",
      "  num_steps_trained: 175240\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 10\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 72.02857142857142\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03625213794456035\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06481755920332129\n",
      "  mean_inference_ms: 1.0109909900373704\n",
      "  mean_raw_obs_processing_ms: 0.10530332316486564\n",
      "time_since_restore: 45.01505923271179\n",
      "time_this_iter_s: 4.991849184036255\n",
      "time_total_s: 45.01505923271179\n",
      "timers:\n",
      "  apply_grad_throughput: 12273.377\n",
      "  apply_grad_time_ms: 0.815\n",
      "  grad_wait_time_ms: 0.947\n",
      "  update_time_ms: 0.65\n",
      "timestamp: 1641330722\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 175240\n",
      "training_iteration: 10\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-12-07\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 492.5485707677553\n",
      "episode_reward_mean: 223.504507150276\n",
      "episode_reward_min: 38.39453996048644\n",
      "episodes_this_iter: 200\n",
      "episodes_total: 1952\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 132.77572631835938\n",
      "        policy_entropy: 4.022569179534912\n",
      "        policy_loss: -15.470800399780273\n",
      "        vf_loss: 19.329919815063477\n",
      "  num_steps_sampled: 194980\n",
      "  num_steps_trained: 194980\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 11\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 71.77142857142857\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03623826140911127\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06474556210554161\n",
      "  mean_inference_ms: 1.0100700277131858\n",
      "  mean_raw_obs_processing_ms: 0.1052155056442022\n",
      "time_since_restore: 50.006309032440186\n",
      "time_this_iter_s: 4.9912497997283936\n",
      "time_total_s: 50.006309032440186\n",
      "timers:\n",
      "  apply_grad_throughput: 11844.301\n",
      "  apply_grad_time_ms: 0.844\n",
      "  grad_wait_time_ms: 1.051\n",
      "  update_time_ms: 0.696\n",
      "timestamp: 1641330727\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 194980\n",
      "training_iteration: 11\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-12-12\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 825.7461545756462\n",
      "episode_reward_mean: 235.69013404088568\n",
      "episode_reward_min: 38.709990217955\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 2144\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 1825.2481689453125\n",
      "        policy_entropy: 4.78081750869751\n",
      "        policy_loss: 132.18128967285156\n",
      "        vf_loss: 2008.6678466796875\n",
      "  num_steps_sampled: 214520\n",
      "  num_steps_trained: 214520\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 12\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 72.42857142857143\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03621738793042245\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06472007183250134\n",
      "  mean_inference_ms: 1.0091403497411353\n",
      "  mean_raw_obs_processing_ms: 0.10510916435373356\n",
      "time_since_restore: 54.99431586265564\n",
      "time_this_iter_s: 4.988006830215454\n",
      "time_total_s: 54.99431586265564\n",
      "timers:\n",
      "  apply_grad_throughput: 12535.653\n",
      "  apply_grad_time_ms: 0.798\n",
      "  grad_wait_time_ms: 0.953\n",
      "  update_time_ms: 0.644\n",
      "timestamp: 1641330732\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 214520\n",
      "training_iteration: 12\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-12-17\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 585.2165629633932\n",
      "episode_reward_mean: 209.66430369064656\n",
      "episode_reward_min: -4932.015122510871\n",
      "episodes_this_iter: 200\n",
      "episodes_total: 2344\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 83.27935791015625\n",
      "        policy_entropy: 6.378554821014404\n",
      "        policy_loss: 0.6154533624649048\n",
      "        vf_loss: 8.985947608947754\n",
      "  num_steps_sampled: 234090\n",
      "  num_steps_trained: 234090\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 13\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 71.21428571428571\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03623798107274338\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06475382280216875\n",
      "  mean_inference_ms: 1.0090928941441768\n",
      "  mean_raw_obs_processing_ms: 0.10509389864835506\n",
      "time_since_restore: 59.98633599281311\n",
      "time_this_iter_s: 4.992020130157471\n",
      "time_total_s: 59.98633599281311\n",
      "timers:\n",
      "  apply_grad_throughput: 12387.56\n",
      "  apply_grad_time_ms: 0.807\n",
      "  grad_wait_time_ms: 0.951\n",
      "  update_time_ms: 0.662\n",
      "timestamp: 1641330737\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 234090\n",
      "training_iteration: 13\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-12-22\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 587.2982063101589\n",
      "episode_reward_mean: 253.8870841728115\n",
      "episode_reward_min: 27.044407689806796\n",
      "episodes_this_iter: 200\n",
      "episodes_total: 2544\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 1900.2542724609375\n",
      "        policy_entropy: 3.816532850265503\n",
      "        policy_loss: 110.92401123046875\n",
      "        vf_loss: 2841.33642578125\n",
      "  num_steps_sampled: 254000\n",
      "  num_steps_trained: 254000\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 14\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 75.94285714285715\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0362248260786809\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06472088202052324\n",
      "  mean_inference_ms: 1.0084214483815266\n",
      "  mean_raw_obs_processing_ms: 0.1050016125269546\n",
      "time_since_restore: 64.97487378120422\n",
      "time_this_iter_s: 4.988537788391113\n",
      "time_total_s: 64.97487378120422\n",
      "timers:\n",
      "  apply_grad_throughput: 11932.926\n",
      "  apply_grad_time_ms: 0.838\n",
      "  grad_wait_time_ms: 0.88\n",
      "  update_time_ms: 0.667\n",
      "timestamp: 1641330742\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 254000\n",
      "training_iteration: 14\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-12-27\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 982.9833213725517\n",
      "episode_reward_mean: 251.57961348430484\n",
      "episode_reward_min: -1045.8500410052002\n",
      "episodes_this_iter: 197\n",
      "episodes_total: 2741\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 515.8468017578125\n",
      "        policy_entropy: 7.8974151611328125\n",
      "        policy_loss: -8.63320541381836\n",
      "        vf_loss: 38.29672622680664\n",
      "  num_steps_sampled: 273860\n",
      "  num_steps_trained: 273860\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 15\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 75.98571428571428\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03621352558375541\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06469640228413645\n",
      "  mean_inference_ms: 1.0078022826146162\n",
      "  mean_raw_obs_processing_ms: 0.10495181915194216\n",
      "time_since_restore: 69.9659788608551\n",
      "time_this_iter_s: 4.991105079650879\n",
      "time_total_s: 69.9659788608551\n",
      "timers:\n",
      "  apply_grad_throughput: 12083.153\n",
      "  apply_grad_time_ms: 0.828\n",
      "  grad_wait_time_ms: 0.952\n",
      "  update_time_ms: 0.694\n",
      "timestamp: 1641330747\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 273860\n",
      "training_iteration: 15\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-12-32\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 1433.5910427099232\n",
      "episode_reward_mean: 270.8008936702981\n",
      "episode_reward_min: -571.0727467992245\n",
      "episodes_this_iter: 196\n",
      "episodes_total: 2937\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 531.6338500976562\n",
      "        policy_entropy: 7.869846343994141\n",
      "        policy_loss: 11.185101509094238\n",
      "        vf_loss: 7.0609660148620605\n",
      "  num_steps_sampled: 293760\n",
      "  num_steps_trained: 293760\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 16\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 61.125\n",
      "  ram_util_percent: 89.7875\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03620592794167563\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06469114219036895\n",
      "  mean_inference_ms: 1.0073181139292375\n",
      "  mean_raw_obs_processing_ms: 0.1048879331542455\n",
      "time_since_restore: 74.95587110519409\n",
      "time_this_iter_s: 4.989892244338989\n",
      "time_total_s: 74.95587110519409\n",
      "timers:\n",
      "  apply_grad_throughput: 12039.451\n",
      "  apply_grad_time_ms: 0.831\n",
      "  grad_wait_time_ms: 0.937\n",
      "  update_time_ms: 0.636\n",
      "timestamp: 1641330752\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 293760\n",
      "training_iteration: 16\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-12-37\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 790.9341767355264\n",
      "episode_reward_mean: 269.9491732833957\n",
      "episode_reward_min: -102.12996256039331\n",
      "episodes_this_iter: 199\n",
      "episodes_total: 3136\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 91154.1796875\n",
      "        policy_entropy: 6.699647426605225\n",
      "        policy_loss: -675.6360473632812\n",
      "        vf_loss: 239158.953125\n",
      "  num_steps_sampled: 313620\n",
      "  num_steps_trained: 313620\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 17\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 71.2\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03621127622792181\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06468684270697275\n",
      "  mean_inference_ms: 1.0072833249358646\n",
      "  mean_raw_obs_processing_ms: 0.10487486974616064\n",
      "time_since_restore: 79.9459981918335\n",
      "time_this_iter_s: 4.990127086639404\n",
      "time_total_s: 79.9459981918335\n",
      "timers:\n",
      "  apply_grad_throughput: 12769.604\n",
      "  apply_grad_time_ms: 0.783\n",
      "  grad_wait_time_ms: 0.965\n",
      "  update_time_ms: 0.666\n",
      "timestamp: 1641330757\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 313620\n",
      "training_iteration: 17\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-12-42\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 1020.8448285994526\n",
      "episode_reward_mean: 272.1017498371666\n",
      "episode_reward_min: -334.5986355896511\n",
      "episodes_this_iter: 200\n",
      "episodes_total: 3336\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 1364.86328125\n",
      "        policy_entropy: 4.465506553649902\n",
      "        policy_loss: 11.619669914245605\n",
      "        vf_loss: 132.83900451660156\n",
      "  num_steps_sampled: 333460\n",
      "  num_steps_trained: 333460\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 18\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 72.04285714285716\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036220203671737096\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06471361763626553\n",
      "  mean_inference_ms: 1.0070955038948126\n",
      "  mean_raw_obs_processing_ms: 0.10484197855943841\n",
      "time_since_restore: 84.93523716926575\n",
      "time_this_iter_s: 4.989238977432251\n",
      "time_total_s: 84.93523716926575\n",
      "timers:\n",
      "  apply_grad_throughput: 12718.877\n",
      "  apply_grad_time_ms: 0.786\n",
      "  grad_wait_time_ms: 0.942\n",
      "  update_time_ms: 0.69\n",
      "timestamp: 1641330762\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 333460\n",
      "training_iteration: 18\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-12-47\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 869.1221400666929\n",
      "episode_reward_mean: 302.92479651474974\n",
      "episode_reward_min: -143.50760724422403\n",
      "episodes_this_iter: 200\n",
      "episodes_total: 3536\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 3541.314208984375\n",
      "        policy_entropy: 1.0535008907318115\n",
      "        policy_loss: 2.455331802368164\n",
      "        vf_loss: 4543.96142578125\n",
      "  num_steps_sampled: 353270\n",
      "  num_steps_trained: 353270\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 19\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 73.17142857142858\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0362306986943822\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06474079614505306\n",
      "  mean_inference_ms: 1.0071406658085067\n",
      "  mean_raw_obs_processing_ms: 0.10485108308345115\n",
      "time_since_restore: 89.92456293106079\n",
      "time_this_iter_s: 4.989325761795044\n",
      "time_total_s: 89.92456293106079\n",
      "timers:\n",
      "  apply_grad_throughput: 12977.024\n",
      "  apply_grad_time_ms: 0.771\n",
      "  grad_wait_time_ms: 0.911\n",
      "  update_time_ms: 0.647\n",
      "timestamp: 1641330767\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 353270\n",
      "training_iteration: 19\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-12-52\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 1219.7120800291748\n",
      "episode_reward_mean: 306.1508634531121\n",
      "episode_reward_min: -403.2474700596301\n",
      "episodes_this_iter: 199\n",
      "episodes_total: 3735\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 16924.630859375\n",
      "        policy_entropy: 3.8895435333251953\n",
      "        policy_loss: -22.728025436401367\n",
      "        vf_loss: 753.2678833007812\n",
      "  num_steps_sampled: 373120\n",
      "  num_steps_trained: 373120\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 20\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 59.87142857142857\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03621852965720155\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0647188336056967\n",
      "  mean_inference_ms: 1.0069025179377376\n",
      "  mean_raw_obs_processing_ms: 0.1048369139452019\n",
      "time_since_restore: 94.91267776489258\n",
      "time_this_iter_s: 4.988114833831787\n",
      "time_total_s: 94.91267776489258\n",
      "timers:\n",
      "  apply_grad_throughput: 12484.162\n",
      "  apply_grad_time_ms: 0.801\n",
      "  grad_wait_time_ms: 0.895\n",
      "  update_time_ms: 0.665\n",
      "timestamp: 1641330772\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 373120\n",
      "training_iteration: 20\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-12-57\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 1042.8767052451753\n",
      "episode_reward_mean: 337.56996001432225\n",
      "episode_reward_min: -432.09692951974444\n",
      "episodes_this_iter: 195\n",
      "episodes_total: 3930\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 3914.077880859375\n",
      "        policy_entropy: 5.195038795471191\n",
      "        policy_loss: 59.48219299316406\n",
      "        vf_loss: 1656.20361328125\n",
      "  num_steps_sampled: 393010\n",
      "  num_steps_trained: 393010\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 21\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 60.85714285714285\n",
      "  ram_util_percent: 89.74285714285713\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03621645441584699\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06472162692799882\n",
      "  mean_inference_ms: 1.006703970492125\n",
      "  mean_raw_obs_processing_ms: 0.10480719538187748\n",
      "time_since_restore: 99.90093684196472\n",
      "time_this_iter_s: 4.9882590770721436\n",
      "time_total_s: 99.90093684196472\n",
      "timers:\n",
      "  apply_grad_throughput: 12055.023\n",
      "  apply_grad_time_ms: 0.83\n",
      "  grad_wait_time_ms: 0.925\n",
      "  update_time_ms: 0.674\n",
      "timestamp: 1641330777\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 393010\n",
      "training_iteration: 21\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-13-02\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 1685.5263166234467\n",
      "episode_reward_mean: -2.433412969709563e+17\n",
      "episode_reward_min: -3.817068618140875e+19\n",
      "episodes_this_iter: 198\n",
      "episodes_total: 4128\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 2613159936.0\n",
      "        policy_entropy: 11.564379692077637\n",
      "        policy_loss: -162256496.0\n",
      "        vf_loss: 973435614265344.0\n",
      "  num_steps_sampled: 412740\n",
      "  num_steps_trained: 412740\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 22\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 61.728571428571435\n",
      "  ram_util_percent: 89.77142857142857\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03621519216862667\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0647150118968532\n",
      "  mean_inference_ms: 1.006677411242787\n",
      "  mean_raw_obs_processing_ms: 0.1048188341200165\n",
      "time_since_restore: 104.89013290405273\n",
      "time_this_iter_s: 4.989196062088013\n",
      "time_total_s: 104.89013290405273\n",
      "timers:\n",
      "  apply_grad_throughput: 11734.617\n",
      "  apply_grad_time_ms: 0.852\n",
      "  grad_wait_time_ms: 0.952\n",
      "  update_time_ms: 0.655\n",
      "timestamp: 1641330782\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 412740\n",
      "training_iteration: 22\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-13-07\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 2877.5047210416137\n",
      "episode_reward_mean: -3242.6979489311225\n",
      "episode_reward_min: -351353.2601701965\n",
      "episodes_this_iter: 200\n",
      "episodes_total: 4328\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 801.6730346679688\n",
      "        policy_entropy: 17.589862823486328\n",
      "        policy_loss: 47.53169250488281\n",
      "        vf_loss: 147.44967651367188\n",
      "  num_steps_sampled: 432360\n",
      "  num_steps_trained: 432360\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 23\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 73.05714285714286\n",
      "  ram_util_percent: 89.77142857142857\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03621441386574711\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06471629688276241\n",
      "  mean_inference_ms: 1.0065562208662917\n",
      "  mean_raw_obs_processing_ms: 0.10479297932647728\n",
      "time_since_restore: 109.87719178199768\n",
      "time_this_iter_s: 4.987058877944946\n",
      "time_total_s: 109.87719178199768\n",
      "timers:\n",
      "  apply_grad_throughput: 12655.555\n",
      "  apply_grad_time_ms: 0.79\n",
      "  grad_wait_time_ms: 0.992\n",
      "  update_time_ms: 0.664\n",
      "timestamp: 1641330787\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 432360\n",
      "training_iteration: 23\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-13-12\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 4415.633722506491\n",
      "episode_reward_mean: -68245.52441236991\n",
      "episode_reward_min: -11986788.435474178\n",
      "episodes_this_iter: 184\n",
      "episodes_total: 4512\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 343050.34375\n",
      "        policy_entropy: 17.770748138427734\n",
      "        policy_loss: 1319.035888671875\n",
      "        vf_loss: 51825.53125\n",
      "  num_steps_sampled: 450770\n",
      "  num_steps_trained: 450770\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 24\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 74.2\n",
      "  ram_util_percent: 89.8375\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036257436598940596\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06477378621978121\n",
      "  mean_inference_ms: 1.0079163006885097\n",
      "  mean_raw_obs_processing_ms: 0.10490070220200441\n",
      "time_since_restore: 114.8659770488739\n",
      "time_this_iter_s: 4.988785266876221\n",
      "time_total_s: 114.8659770488739\n",
      "timers:\n",
      "  apply_grad_throughput: 12710.782\n",
      "  apply_grad_time_ms: 0.787\n",
      "  grad_wait_time_ms: 0.933\n",
      "  update_time_ms: 0.658\n",
      "timestamp: 1641330792\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 450770\n",
      "training_iteration: 24\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-13-17\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 4793.850293718167\n",
      "episode_reward_mean: -162109.68662248665\n",
      "episode_reward_min: -21783712.341343977\n",
      "episodes_this_iter: 184\n",
      "episodes_total: 4696\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 360.1957702636719\n",
      "        policy_entropy: 14.260562896728516\n",
      "        policy_loss: -11.382987976074219\n",
      "        vf_loss: 25.088783264160156\n",
      "  num_steps_sampled: 469720\n",
      "  num_steps_trained: 469720\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 25\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 72.52857142857144\n",
      "  ram_util_percent: 89.74285714285715\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03628505203493466\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06483078352467585\n",
      "  mean_inference_ms: 1.0088546292457206\n",
      "  mean_raw_obs_processing_ms: 0.10497181940995655\n",
      "time_since_restore: 119.85338115692139\n",
      "time_this_iter_s: 4.987404108047485\n",
      "time_total_s: 119.85338115692139\n",
      "timers:\n",
      "  apply_grad_throughput: 12422.414\n",
      "  apply_grad_time_ms: 0.805\n",
      "  grad_wait_time_ms: 0.896\n",
      "  update_time_ms: 0.688\n",
      "timestamp: 1641330797\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 469720\n",
      "training_iteration: 25\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-13-22\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 7748.755944531782\n",
      "episode_reward_mean: -3323.685450794914\n",
      "episode_reward_min: -145832.06789724118\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 4888\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 54974.69921875\n",
      "        policy_entropy: 10.691338539123535\n",
      "        policy_loss: 713.7574462890625\n",
      "        vf_loss: 44961.41796875\n",
      "  num_steps_sampled: 488610\n",
      "  num_steps_trained: 488610\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 26\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 74.78571428571429\n",
      "  ram_util_percent: 89.97142857142858\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03633343158711854\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06488169706591611\n",
      "  mean_inference_ms: 1.0096127168200884\n",
      "  mean_raw_obs_processing_ms: 0.10504174842936864\n",
      "time_since_restore: 124.84137916564941\n",
      "time_this_iter_s: 4.987998008728027\n",
      "time_total_s: 124.84137916564941\n",
      "timers:\n",
      "  apply_grad_throughput: 12202.322\n",
      "  apply_grad_time_ms: 0.82\n",
      "  grad_wait_time_ms: 0.953\n",
      "  update_time_ms: 0.619\n",
      "timestamp: 1641330802\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 488610\n",
      "training_iteration: 26\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-13-27\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 2965.6812099688527\n",
      "episode_reward_mean: -183.57120981409966\n",
      "episode_reward_min: -32379.18774735119\n",
      "episodes_this_iter: 192\n",
      "episodes_total: 5080\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 35.883209228515625\n",
      "        policy_entropy: 8.383049011230469\n",
      "        policy_loss: 13.771961212158203\n",
      "        vf_loss: 2.740166664123535\n",
      "  num_steps_sampled: 508100\n",
      "  num_steps_trained: 508100\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 27\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 63.41428571428572\n",
      "  ram_util_percent: 89.8142857142857\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036338407509394814\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06489806645125366\n",
      "  mean_inference_ms: 1.0096453874311668\n",
      "  mean_raw_obs_processing_ms: 0.10505480115125805\n",
      "time_since_restore: 129.83078408241272\n",
      "time_this_iter_s: 4.989404916763306\n",
      "time_total_s: 129.83078408241272\n",
      "timers:\n",
      "  apply_grad_throughput: 12549.155\n",
      "  apply_grad_time_ms: 0.797\n",
      "  grad_wait_time_ms: 1.032\n",
      "  update_time_ms: 0.806\n",
      "timestamp: 1641330807\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 508100\n",
      "training_iteration: 27\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-13-32\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 1702.9037646195152\n",
      "episode_reward_mean: -9338.422461234471\n",
      "episode_reward_min: -1842310.649359961\n",
      "episodes_this_iter: 200\n",
      "episodes_total: 5280\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 4959.98095703125\n",
      "        policy_entropy: 8.918413162231445\n",
      "        policy_loss: -94.17096710205078\n",
      "        vf_loss: 3276.6875\n",
      "  num_steps_sampled: 527600\n",
      "  num_steps_trained: 527600\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 28\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 77.32857142857142\n",
      "  ram_util_percent: 89.78571428571429\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03634100292613705\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06490939962091169\n",
      "  mean_inference_ms: 1.009703504170641\n",
      "  mean_raw_obs_processing_ms: 0.10504749193479178\n",
      "time_since_restore: 134.81729125976562\n",
      "time_this_iter_s: 4.986507177352905\n",
      "time_total_s: 134.81729125976562\n",
      "timers:\n",
      "  apply_grad_throughput: 12409.183\n",
      "  apply_grad_time_ms: 0.806\n",
      "  grad_wait_time_ms: 0.896\n",
      "  update_time_ms: 0.722\n",
      "timestamp: 1641330812\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 527600\n",
      "training_iteration: 28\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-13-37\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 5211.689035453807\n",
      "episode_reward_mean: 117.7262337282105\n",
      "episode_reward_min: -12379.408223925111\n",
      "episodes_this_iter: 198\n",
      "episodes_total: 5478\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 542.2960815429688\n",
      "        policy_entropy: 7.343398571014404\n",
      "        policy_loss: -4.0095086097717285\n",
      "        vf_loss: 137.30406188964844\n",
      "  num_steps_sampled: 547470\n",
      "  num_steps_trained: 547470\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 29\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 85.35714285714286\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.03633124327055299\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06489236521557075\n",
      "  mean_inference_ms: 1.0094272656226742\n",
      "  mean_raw_obs_processing_ms: 0.10503109228208267\n",
      "time_since_restore: 139.80554914474487\n",
      "time_this_iter_s: 4.988257884979248\n",
      "time_total_s: 139.80554914474487\n",
      "timers:\n",
      "  apply_grad_throughput: 12534.154\n",
      "  apply_grad_time_ms: 0.798\n",
      "  grad_wait_time_ms: 0.851\n",
      "  update_time_ms: 0.651\n",
      "timestamp: 1641330817\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 547470\n",
      "training_iteration: 29\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 0\n",
      "custom_metrics: {}\n",
      "date: 2022-01-04_15-13-42\n",
      "done: false\n",
      "episode_len_mean: 100.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 2197.1752193258408\n",
      "episode_reward_mean: -13849.081604277206\n",
      "episode_reward_min: -1682715.2388277762\n",
      "episodes_this_iter: 194\n",
      "episodes_total: 5672\n",
      "experiment_id: 1909ff1c71264a9da8d6ca287c78d6b3\n",
      "hostname: mw-14.local\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      batch_count: 10\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0001\n",
      "        entropy_coeff: 0.01\n",
      "        grad_gnorm: 847.5951538085938\n",
      "        policy_entropy: 4.74984073638916\n",
      "        policy_loss: -0.8013176321983337\n",
      "        vf_loss: 55.749061584472656\n",
      "  num_steps_sampled: 567270\n",
      "  num_steps_trained: 567270\n",
      "  num_steps_trained_this_iter: 0\n",
      "iterations_since_restore: 30\n",
      "node_ip: 127.0.0.1\n",
      "num_healthy_workers: 8\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.385714285714286\n",
      "  ram_util_percent: 89.79999999999998\n",
      "pid: 47825\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.036324080254322745\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06489606158015422\n",
      "  mean_inference_ms: 1.0090555772959584\n",
      "  mean_raw_obs_processing_ms: 0.10498401373846512\n",
      "time_since_restore: 144.7945580482483\n",
      "time_this_iter_s: 4.989008903503418\n",
      "time_total_s: 144.7945580482483\n",
      "timers:\n",
      "  apply_grad_throughput: 12531.533\n",
      "  apply_grad_time_ms: 0.798\n",
      "  grad_wait_time_ms: 0.957\n",
      "  update_time_ms: 0.656\n",
      "timestamp: 1641330822\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 567270\n",
      "training_iteration: 30\n",
      "trial_id: default\n",
      "\n",
      "checkpoint saved at /Users/mingweima/ray_results/A3C_my-env_2022-01-04_15-11-160hhhuamk/checkpoint_000030/checkpoint-30\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()\n",
    "env = WhitedBasicModel(env_config={\"structural_params\": {\"gamma\": [0.9,0.96],\n",
    "                                                         \"delta\": [0.1, 0.3],\n",
    "                                                         \"theta\": [0.5, 0.8],\n",
    "                                                         \"rho\": [0.3, 0.8],\n",
    "                                                         \"sigma\": [0., 0.15],\n",
    "                                                        }, \n",
    "                                   \"env_params\": {\"psi_func\": lambda i, k: 0.01*i**2/(2*k)\n",
    "                                                 },\n",
    "                                   \"is_mutable\": True,\n",
    "                                  })\n",
    "solver = RaySolver(env=env,\n",
    "                   trainer=A3C_Trainer,\n",
    "                   solver_params={\"verbose\": True, \"episodes\": 30,\n",
    "                                  \"trainer_config\": {\n",
    "                                      \"num_workers\": 8,\n",
    "                                      \"gamma\": env.current_structural_params.get(\"gamma\", 0.99),\n",
    "                                  }\n",
    "                                  })\n",
    "solver.train()\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mingweima/ray_results/A3C_my-env_2022-01-04_15-11-160hhhuamk/checkpoint_000030/checkpoint-30'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.25749457 0.9700405  0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 0.4722991689750693 False {}\n",
      "[1.58129263 0.90323907 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 0.45165213447021 False {}\n",
      "[1.98846686 0.93294728 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 0.35941292909829026 False {}\n",
      "[2.50048637 0.86645037 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 0.3683846258613306 False {}\n",
      "[3.14434814 0.90679449 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 0.19421556033282084 False {}\n",
      "[3.95400071 0.92042851 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 0.1620510988062469 False {}\n",
      "[4.97213459 0.92637265 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 0.038890249128181065 False {}\n",
      "[6.25243235 1.05888259 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 -0.1644733279227797 False {}\n",
      "[7.86239958 1.00871837 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 -0.0675428650036416 False {}\n",
      "[9.88692474 0.87045527 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 -0.6094135275847936 False {}\n",
      "[12.43275452  0.98527032  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.7057453396105382 False {}\n",
      "[15.63412094  0.98713797  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.9910621114099811 False {}\n",
      "[11.43133736  0.99386305  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 0 5.263651479164681 False {}\n",
      "[8.35835171 1.00919724 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.379839742328096 False {}\n",
      "[6.11144924 1.00143743 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 3.6756161808402 False {}\n",
      "[7.68511438 0.96877801 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 -0.21062069480641243 False {}\n",
      "[9.66399002 0.94669491 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 -0.7028812576665859 False {}\n",
      "[7.06610441 0.87314534 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 3.766501172792051 False {}\n",
      "[8.88558769 0.89472556 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 -0.8577638801447076 False {}\n",
      "[11.17357826  0.95207828  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.3066011789789496 False {}\n",
      "[14.05071449  0.89620119  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.7584572500715776 False {}\n",
      "[17.66869736  0.87081504  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -2.9365817870974062 False {}\n",
      "[12.91897678  0.89513725  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 0 5.002412277447571 False {}\n",
      "[9.44608212 0.9219957  0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.24977178041751 False {}\n",
      "[11.87839699  0.96130306  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.3670491282327557 False {}\n",
      "[14.93701935  1.07696152  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.9317884376626342 False {}\n",
      "[18.78322029  1.10322571  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -2.296931009383621 False {}\n",
      "[14.72248268  1.02793002  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 1 5.589091820791616 False {}\n",
      "[18.51344299  1.0273546   0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -2.484751482138541 False {}\n",
      "[13.53663635  1.08124924  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 0 6.071853571172954 False {}\n",
      "[9.89770126 1.00417185 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 5.2814009760972365 False {}\n",
      "[12.44630527  0.9948141   0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.169304858557613 False {}\n",
      "[9.10047436 0.98399079 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.617037848516433 False {}\n",
      "[6.65407372 0.92036343 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 3.774287256127179 False {}\n",
      "[8.3674612  0.88263017 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 -0.593760688783727 False {}\n",
      "[10.52203751  0.82038558  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.1987399613022967 False {}\n",
      "[13.23140526  0.91002256  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -2.115041925495362 False {}\n",
      "[9.6745224  0.83333826 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.3837502324699935 False {}\n",
      "[12.16565895  0.87477434  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.7875515487168783 False {}\n",
      "[15.2982502   0.93853939  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -2.4158857475800306 False {}\n",
      "[11.18575573  0.94433641  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 0 4.938784571552115 False {}\n",
      "[8.17878723 1.04830134 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.10692456023639 False {}\n",
      "[10.2847805   1.01217818  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -0.5480599844125056 False {}\n",
      "[12.93305588  1.03153121  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.2446986834617793 False {}\n",
      "[16.26324844  1.07458115  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.9242174598865063 False {}\n",
      "[12.74730301  0.97554469  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 1 5.01301481368883 False {}\n",
      "[9.32055759 0.93915862 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.5939508458203075 False {}\n",
      "[11.72055054  1.05813658  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.2633552515267348 False {}\n",
      "[14.73852825  1.02671087  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.4503900944390775 False {}\n",
      "[10.77649879  0.96907264  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 0 5.281548616001849 False {}\n",
      "[7.87954712 0.91970587 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.119949189798742 False {}\n",
      "[9.90848732 1.12008643 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 -0.9265232226432136 False {}\n",
      "[12.45986938  1.05196393  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -0.7040644740896624 False {}\n",
      "[9.11039257 1.01302552 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.885514660397923 False {}\n",
      "[11.45626926  1.12122869  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -0.9193286788970512 False {}\n",
      "[8.37658119 1.0673362  0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.947683109006041 False {}\n",
      "[10.53350544  1.16990912  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -0.527804564597782 False {}\n",
      "[13.24582577  0.98796475  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -0.6533252288847811 False {}\n",
      "[16.65655327  0.92319793  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -2.2274638558502167 False {}\n",
      "[12.17891788  1.019068    0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 0 5.1162553178087125 False {}\n",
      "[8.90496635 0.98963773 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.667485299065978 False {}\n",
      "[11.19794655  1.0164628   0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -0.9530660285264503 False {}\n",
      "[8.18770123 1.003685   0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.423534924966012 False {}\n",
      "[10.29598999  0.96525919  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -0.7107346740763343 False {}\n",
      "[8.07010365 0.98623341 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 1 3.4493159620288063 False {}\n",
      "[10.14811134  0.96312255  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -0.7425481811452928 False {}\n",
      "[7.42008352 0.97777718 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 3.9475979930170704 False {}\n",
      "[9.33071518 0.9754948  0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 -0.6034061833925493 False {}\n",
      "[11.73332405  0.90752572  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.1247804428210082 False {}\n",
      "[14.75459099  0.8935141   0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -2.1283344120701377 False {}\n",
      "[11.56480122  0.88647592  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 1 3.8226523122670466 False {}\n",
      "[14.54267502  0.88527614  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -2.1684551420811595 False {}\n",
      "[10.63329506  0.90928632  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 0 4.517051800813393 False {}\n",
      "[7.77483988 0.94677162 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 3.834417292906648 False {}\n",
      "[9.77681923 0.89644581 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 -0.8031509226092135 False {}\n",
      "[12.29429722  0.97675472  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.567362770858209 False {}\n",
      "[15.46001244  0.91608661  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.9882735286786541 False {}\n",
      "[19.44088173  0.93708718  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -3.3066612562899724 False {}\n",
      "[14.21475983  1.03111625  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 0 5.705638210371766 False {}\n",
      "[10.39353085  1.0911634   0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 0 5.188648734912062 False {}\n",
      "[13.06980896  1.03912807  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -0.9467338671021777 False {}\n",
      "[9.55636692 1.01157784 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.968369733255178 False {}\n",
      "[6.98741293 1.02687836 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 3.997298248548633 False {}\n",
      "[8.78663349 0.93906713 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 -0.3336836468368829 False {}\n",
      "[11.04914379  0.91627175  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.1108781601848086 False {}\n",
      "[8.07889938 0.81780481 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 3.9551730322350442 False {}\n",
      "[10.15917206  0.97148293  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.3457257937578047 False {}\n",
      "[7.9628644  0.95876658 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 1 3.4496725871942893 False {}\n",
      "[10.01325893  0.94907075  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -0.8116042433597874 False {}\n",
      "[7.84849596 1.03298533 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 1 3.331300331084985 False {}\n",
      "[9.86944103 0.98807442 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 -0.5208275443329096 False {}\n",
      "[12.41076851  0.94016433  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -1.226312227894144 False {}\n",
      "[15.60647392  1.05654991  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -2.193358871712495 False {}\n",
      "[11.41112232  0.94630778  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 0 5.627705213315181 False {}\n",
      "[8.34357071 1.03990817 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.1657781864916865 False {}\n",
      "[10.49199486  0.96579134  0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -0.6195189349260128 False {}\n",
      "[7.67152405 1.12580705 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.0396638685499555 False {}\n",
      "[9.64690018 1.07432091 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 10 -0.15648946905973826 False {}\n",
      "[12.13092422  1.0801003   0.9427547   0.26882122  0.60876427  0.6685332\n",
      "  0.06871083] 10 -0.8210088683096215 False {}\n",
      "[8.869874   1.10635865 0.9427547  0.26882122 0.60876427 0.6685332\n",
      " 0.06871083] 0 4.935145514882025 True {}\n"
     ]
    }
   ],
   "source": [
    "# run until episode ends\n",
    "episode_reward = 0\n",
    "done = False\n",
    "obs = env.reset()\n",
    "while not done:\n",
    "    action = solver.act(obs)\n",
    "    obs, reward, done, info = env.step(action, resample_param=False)\n",
    "    episode_reward += reward\n",
    "    print(obs, action, reward, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test trained agent for a single episode. Return the episode reward\"\"\"\n",
    "cp = []\n",
    "for eps in range(50):\n",
    "      # instantiate env class\n",
    "      episode_reward = 0\n",
    "      done = False\n",
    "      obs = env.reset()\n",
    "      # run until episode ends\n",
    "      caps = []\n",
    "      while not done:\n",
    "          action = solver.trainer.compute_single_action(obs, clip_action=True)\n",
    "          obs, reward, done, info = env.step(action, resample_param=False)\n",
    "          episode_reward += reward\n",
    "          #print(action, obs, reward, done)\n",
    "          caps += [obs[0]]\n",
    "      cp += [ [caps] ]\n",
    "cp = np.squeeze(np.array(cp)).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(cp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
